{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sedona.spark import *\n",
    "from contextlib import contextmanager\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import functions as F\n",
    "import time\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import sys\n",
    "import io\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import fiona\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Button, Layout\n",
    "from IPython.display import *\n",
    "from io import StringIO\n",
    "import sys\n",
    "\n",
    "\n",
    "class Enricher:\n",
    "\n",
    "    def __init__(self, crs=\"EPSG:3035\"):\n",
    "        self.crs = crs if type(crs) is not int else f\"EPSG:{crs}\"\n",
    "        self.cores = None\n",
    "        self.res = None\n",
    "        self.sedona = None\n",
    "        self.res_agr = None\n",
    "        self.df1 = None\n",
    "        self.df2 = None\n",
    "        self.dfs_list = {}\n",
    "\n",
    "            \n",
    "    def setup_cluster(self, which=\"wherobots\", ex_mem=26, dr_mem=24, log_level=None):\n",
    "        if which == \"wherobots\":\n",
    "            config = SedonaContext.builder().getOrCreate()\n",
    "            self.sedona = SedonaContext.create(config)\n",
    "            \n",
    "            self.cores = self.sedona.sparkContext.defaultParallelism\n",
    "            print(f\"Wherobots setup started with {self.cores} cores for parellelism.\")\n",
    "        elif which == \"sedona\":\n",
    "            # config = SedonaContext.builder() .\\\n",
    "            #     config(\"spark.executor.memory\", f\"{ex_mem}g\").\\\n",
    "            #     config(\"spark.driver.memory\", f\"{dr_mem}g\").\\\n",
    "            #     config('spark.jars.packages',\\\n",
    "            #         'org.apache.sedona:sedona-spark-shaded-3.5_2.12:1.7.0,'\\\n",
    "            #         'org.datasyslab:geotools-wrapper:1.7.0-28.5').\\\n",
    "            #     getOrCreate()\n",
    "\n",
    "            config = SedonaContext.builder() \\\n",
    "                .config(\"spark.executor.memory\", f\"{ex_mem}g\") \\\n",
    "                .config(\"spark.driver.memory\", f\"{dr_mem}g\") \\\n",
    "                .config(\"spark.local.dir\", \"./tmp_spark_spills\") \\\n",
    "                .config(\"spark.driver.maxResultSize\", \"4g\") \\\n",
    "                .config('spark.jars.packages',\n",
    "                    'org.apache.sedona:sedona-spark-shaded-3.5_2.12:1.7.0,'\n",
    "                    'org.datasyslab:geotools-wrapper:1.7.0-28.5') \\\n",
    "                .getOrCreate()\n",
    "\n",
    "\n",
    "            self.sedona = SedonaContext.create(config)\n",
    "            \n",
    "            if log_level in [\"OFF\", \"ERROR\", \"WARN\", \"INFO\", \"DEBUG\"]:\n",
    "                self.sedona.sparkContext.setLogLevel(log_level)\n",
    "                \n",
    "            self.cores = self.sedona.sparkContext.defaultParallelism\n",
    "            print(f\"Sedona initialized with {self.cores} cores for parellelism.\")\n",
    "        else:\n",
    "            raise ValueError(\"Invalid 'which'. Choose either 'wherobots' or 'sedona'\")\n",
    "        \n",
    "    @contextmanager\n",
    "    def get_time(self, task_name):\n",
    "        start = time.time()\n",
    "        yield\n",
    "        elapsed = time.time() - start\n",
    "    \n",
    "        print(f\"{task_name}... DONE in {(elapsed/60):.2f} min\" \\\n",
    "              if elapsed >= 60 else f\"{task_name}... DONE in {elapsed:.2f} sec\")\n",
    "\n",
    "    \n",
    "    def load(self, datasets, silent=True):\n",
    "        print(\"\\nLoading datasets...\")\n",
    "        print(f\"Make sure the geometry column is named \\\"geometry\\\" in the datasets\")\n",
    "    \n",
    "        self.datasets = {}\n",
    "        for name, (path, fformat) in datasets.items():\n",
    "            if fformat == \"geoparquet\":\n",
    "                gdf = gpd.read_parquet(path)\n",
    "                crs = f\"EPSG:{gdf.crs.to_epsg()}\"\n",
    "                print(f\"Loaded '{name}': {gdf.shape}, '{crs}'\")\n",
    "            elif fformat == \"geopackage\":\n",
    "                layers = fiona.listlayers(path)\n",
    "                if layers:\n",
    "                    self.dfs_list[name] = self.sedona.read.format(fformat).option(\"tableName\", layers[0]).load(path)\n",
    "                    gdf = gpd.read_file(f'{path}', engine='pyogrio', use_arrow=True)\n",
    "                    crs = gdf.crs\n",
    "                    print(f\"Loaded '{name}': {gdf.shape}, '{crs}'\")\n",
    "                else:\n",
    "                    print(f\"No layers found in GeoPackage '{name}'\")\n",
    "            else:\n",
    "                gdf = gpd.read_file(path)\n",
    "                crs = gdf.crs\n",
    "                self.dfs_list[name] = self.sedona.read.format(fformat).load(path)\n",
    "                print(f\"Loaded '{name}': {gdf.shape}, '{crs}'\")\n",
    "            \n",
    "            self.datasets[name] = (path, fformat, crs)\n",
    "\n",
    "            \n",
    "        print(f\"{len(self.dfs_list)} datasets loaded. \\n\")\n",
    "        \n",
    "        if not silent:\n",
    "            for name, df in self.dfs_list.items():\n",
    "                print(f\"\\n Dataset: \\\"{name}\\\", count: {df.count()}\")\n",
    "    \n",
    "                geometry_types = df.select(F.expr(\"ST_GeometryType(geometry)\")).distinct().collect()\n",
    "                \n",
    "                res_string = [\n",
    "                    f\"{geometry_type} ({(df.filter(F.expr(f'ST_GeometryType(geometry) = \\'{geometry_type}\\'')).count() / df.count()) * 100:.2f}%)\"\n",
    "                    for row in geometry_types if (geometry_type := row[0])\n",
    "                ]\n",
    "                \n",
    "                print(f\"\\\"{name}\\\" has geometries of type(s): {', '.join(res_string)}\")\n",
    "                df.printSchema()\n",
    "\n",
    "    def force_repartition(self, skip=[]):\n",
    "        for name, df in self.dfs_list.items():\n",
    "            if name not in skip:\n",
    "                self.dfs_list[name] = df.repartition(self.cores)\n",
    "    \n",
    "    def inspect_partitions(self):\n",
    "        for name, df in self.dfs_list.items():\n",
    "            print(f\"'{name}' partitions: {df.rdd.getNumPartitions()}\")\n",
    "            print(f\"'{name}' distribution: {df.rdd.glom().map(len).collect()}\")\n",
    "\n",
    "    \n",
    "    def transform(self, target=None, lazy=True):\n",
    "        if target is None:\n",
    "            target = self.crs\n",
    "        elif type(target) is int:\n",
    "            self.crs = f\"EPSG:{target}\"\n",
    "            target = self.crs\n",
    "        else:\n",
    "            self.crs = target\n",
    "        \n",
    "        print()\n",
    "        print(\"Transforming CRS...\")\n",
    "        for name, df in self.dfs_list.items():\n",
    "            df = df.withColumn(\"geometry\", F.expr(f\"ST_Transform(geometry, '{self.datasets[name][2]}', '{target}')\"))\n",
    "            print(f\"Changed CRS of '{name}': '{self.datasets[name][2]}' to '{target}'\")\n",
    "            self.dfs_list[name] = df\n",
    "            \n",
    "            if not lazy:\n",
    "                self._make_cache(self.dfs_list.values())\n",
    "            \n",
    "    def fix_geometries(self):\n",
    "        for name, df in self.dfs_list.items():\n",
    "            invalid_count = df.filter(F.expr(\"NOT ST_IsValid(geometry)\")).count()\n",
    "            print(f\"'{name}' has {((invalid_count / df.count()) * 100 if df.count() > 0 else 0):.2f}% invalid geometries.\")\n",
    "            \n",
    "            if invalid_count > 0:\n",
    "                df = df.withColumn(\"geometry\", F.expr(\"ST_MakeValid(geometry)\"))\n",
    "                print(f\"Fixed {invalid_count} geometries in '{name}'\")\n",
    "            else:\n",
    "                print(f\"Nothing to fix in '{name}'\")\n",
    "            \n",
    "            self.dfs_list[name] = df\n",
    "\n",
    "    \n",
    "    def _make_cache(self, dfs=[]):\n",
    "        for df in dfs:\n",
    "            if isinstance(df, DataFrame):\n",
    "                if df.storageLevel != StorageLevel.NONE:\n",
    "                    df.unpersist()\n",
    "                df.cache()\n",
    "            # print(f\"Dataset cached. {df.count()} rows.\")\n",
    "\n",
    "    \n",
    "    def clear_memory(self, *keep):\n",
    "        if self.res.storageLevel != StorageLevel.NONE:\n",
    "            self.res.unpersist()\n",
    "        self.res = None\n",
    "\n",
    "    def join_chey_simple(self, selected_aggs, df1_name, df2_name):\n",
    "        self.res_agr = self.dfs_list[df1_name].alias(\"df1\").join(\n",
    "            self.dfs_list[df2_name].alias(\"df2\"), F.expr(\"ST_Intersects(df1.geometry, df2.geometry)\")\n",
    "        ).select(\n",
    "            F.expr(\"df1.geometry\").alias(\"df1_geom\"),\n",
    "            F.expr(\"df2.geometry\").alias(\"df2_geom\"),\n",
    "            *[f\"df1.{c}\" for c in self.dfs_list[df1_name].columns if c != \"geometry\"],\n",
    "            *[f\"df2.{c}\" for c in self.dfs_list[df2_name].columns if c != \"geometry\" and c not in self.dfs_list[df1_name].columns]\n",
    "        )\n",
    "    \n",
    "    def join_chey_new(self, selected_aggs, df1_name, df2_name, group_by=None, pred=\"ST_Intersects\", rel_str=\"2********\", make_geom=True, ratio=True, madre=False, cache=True, grid_area=None):\n",
    "        \n",
    "        # self.df1 = self.dfs_list[df1_name]\n",
    "        # self.df2 = self.dfs_list[df2_name]\n",
    "    \n",
    "        if self.res_agr is None:\n",
    "            join_expr = f\"{pred}(df1.geometry, df2.geometry)\"\n",
    "            if pred == \"ST_Relate\":\n",
    "                join_expr = f\"{pred}(df1.geometry, df2.geometry, '{rel_str}')\"\n",
    "        \n",
    "            self.res = self.dfs_list[df1_name].alias(\"df1\").join(\n",
    "                self.dfs_list[df2_name].alias(\"df2\"), F.expr(join_expr)\n",
    "            ).select(\n",
    "                F.expr(\"df1.geometry\").alias(\"df1_geom\"),\n",
    "                F.expr(\"df2.geometry\").alias(\"df2_geom\"),\n",
    "                *[f\"df1.{c}\" for c in self.dfs_list[df1_name].columns if c != \"geometry\"],\n",
    "                *[f\"df2.{c}\" for c in self.dfs_list[df2_name].columns if c != \"geometry\" and c not in self.dfs_list[df1_name].columns]\n",
    "            )\n",
    "\n",
    "            \n",
    "            self.res = self.res.withColumn(\"intr_geometry\", F.expr(\"ST_Intersection(df1_geom, df2_geom)\"))\n",
    "            if ratio:\n",
    "                if grid_area > 0:\n",
    "                    self.res = self.res.withColumn(\"intr_ratio\", F.expr(f\"ST_Area(intr_geometry) / {grid_area}\"))\n",
    "                else:\n",
    "                    self.res = self.res.withColumn(\"intr_ratio\", F.expr(\"ST_Area(intr_geometry) / ST_Area(df2_geom)\"))\n",
    "\n",
    "                agg_exprs = []\n",
    "                for col_name, agg_func in selected_aggs.items():\n",
    "                    if agg_func == \"sum\":\n",
    "                        agg_exprs.append(F.sum(F.col(col_name) * F.col(\"intr_ratio\")).alias(f\"{col_name}_agr_{agg_func}\"))\n",
    "                    elif agg_func == \"mean\":\n",
    "                        agg_exprs.append(F.mean(F.col(col_name) * F.col(\"intr_ratio\")).alias(f\"{col_name}_agr_{agg_func}\"))\n",
    "                    elif agg_func == \"min\":\n",
    "                        agg_exprs.append(F.min(F.col(col_name) * F.col(\"intr_ratio\")).alias(f\"{col_name}_agr_{agg_func}\"))\n",
    "                    elif agg_func == \"max\":\n",
    "                        agg_exprs.append(F.max(F.col(col_name) * F.col(\"intr_ratio\")).alias(f\"{col_name}_agr_{agg_func}\"))\n",
    "                    elif agg_func == \"count\":\n",
    "                        agg_exprs.append(F.count(F.col(col_name)).alias(f\"{col_name}_agr_{agg_func}\"))\n",
    "                    elif agg_func == \"first\":\n",
    "                        agg_exprs.append(F.first(F.col(col_name)).alias(f\"{col_name}_agr_{agg_func}\"))\n",
    "                    else:\n",
    "                        raise ValueError(f\"Unsupported aggregation function: {agg_func}\")\n",
    "                    \n",
    "                df1_cols = [F.first(F.col(f\"df1.{c}\")).alias(c) for c in self.dfs_list[df1_name].columns if c != group_by and c != \"geometry\"]\n",
    "                df1_cols.append(F.first(F.col(\"df1_geom\")).alias(\"geometry\"))\n",
    "                self.res_agr = self.res.groupBy(group_by).agg(*df1_cols, *agg_exprs)\n",
    "\n",
    "                print(f\"Aggregation completed. {self.res_agr.count()} rows.\")\n",
    "            \n",
    "            if madre:\n",
    "                columns_to_drop = [\"df1_geom\", \"df2_geom\"] + list(selected_aggs.keys())\n",
    "                self.res = self.res.drop(*columns_to_drop)\n",
    "                self.res = self.res.join(self.res_agr.drop(\"geometry\"), on=group_by, how=\"left\")\n",
    "                self.res = self.res.withColumnRenamed(\"intr_geometry\", \"geometry\")\n",
    "    \n",
    "        if cache:\n",
    "            if madre:\n",
    "                self.res.cache()\n",
    "                self.res.count()\n",
    "            self.res_agr.cache()\n",
    "            self.res_agr.count()\n",
    "            \n",
    "    \n",
    "        return self.res_agr\n",
    "    \n",
    "    \n",
    "\n",
    "    def export(self, df=\"default\", path=\"outputs\", name=\"unnamed\", how=\"repartition\", num=None, clear=False):\n",
    "        if num is None:\n",
    "            num = self.cores\n",
    "        if how == \"repartition\":\n",
    "            self.res = self.res.repartition(num)\n",
    "        elif how == \"coalesce\":\n",
    "            self.res = self.res.coalesce(num)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid 'how'. Choose either 'repartition' or 'coalesce'\")\n",
    "\n",
    "        if df == \"default\":\n",
    "            self.res_agr.write.mode(\"overwrite\").format(\"geoparquet\").save(f\"./{path}/\" + f\"/{name}_agr\")\n",
    "        else:\n",
    "            self.res.write.mode(\"overwrite\").format(\"geoparquet\").save(f\"./{path}/\" + f\"/{name}_madre\")\n",
    "        \n",
    "        if clear:\n",
    "            self.clear_memory()\n",
    "\n",
    "\n",
    "\n",
    "class EnricherUI:\n",
    "    def __init__(self, enricher):\n",
    "        self.enricher = enricher\n",
    "        self.loaded_dataframes = {}\n",
    "        self.selected_cols = []\n",
    "        self.group_by_col = None\n",
    "        self._init_ui()\n",
    "        self.loaded_dataframes = self.list_dataframes_in_memory()\n",
    "        self.df1_dropdown.options = list(self.loaded_dataframes.keys())\n",
    "        self.df2_dropdown.options = list(self.loaded_dataframes.keys())\n",
    "        self.df1_dropdown.disabled = False\n",
    "        self.df2_dropdown.disabled = False        \n",
    "        self.selected_aggs = {}\n",
    "        self.agg_options = [\"sum\", \"count\", \"mean\", \"min\", \"max\", \"first\"]\n",
    "\n",
    "    def list_dataframes_in_memory(self):\n",
    "        # return {name: obj for name, obj in globals().items() if isinstance(obj, pd.DataFrame)}\n",
    "        return {name: df for name, df in self.enricher.dfs_list.items()}\n",
    "    \n",
    "    def _init_ui(self):\n",
    "        # Heading:\n",
    "        self.heading = widgets.HTML(value=\"<h1>Enrich with Overlay & Aggregation</h1>\")\n",
    "\n",
    "        # First line: Enrich <df1> with <df2>\n",
    "        self.df1_dropdown = widgets.Dropdown(options=[], description=\"df1:\", disabled=True, style={'description_width': 'initial'}, layout=widgets.Layout(margin=\"5px 20px\", width=\"150px\"))\n",
    "        self.df2_dropdown = widgets.Dropdown(options=[], description=\"df2:\", disabled=True, style={'description_width': 'initial'}, layout=widgets.Layout(margin=\"5px 20px\", width=\"150px\"))\n",
    "        self.load_status = widgets.HTML(value=\"<small>Status: No dataframes loaded.</small>\")\n",
    "        self.load_button = widgets.Button(description=\"Load\", disabled=True, layout=widgets.Layout(margin=\"5px 0px\", width=\"100px\", border=\"2px solid black\"))\n",
    "        self.load_button.style.font_weight = 'bold'\n",
    "\n",
    "        # Second line: with attributes: <cols>\n",
    "        self.cols_dropdown = widgets.SelectMultiple(options=[], description=\"aggr cols:\", disabled=True, style={'description_width': 'initial'})\n",
    "        self.agg_table_output = widgets.Output()        \n",
    "        \n",
    "        # Third line: unique id: <col>\n",
    "        self.group_by_dropdown = widgets.Dropdown(options=[], description=\"unique id:\", disabled=True, style={'description_width': 'initial'}, layout=widgets.Layout(margin=\"5px 20px\", width=\"250px\"))\n",
    "        \n",
    "        self.agg_status = widgets.HTML(value=\"\")\n",
    "\n",
    "        # Advanced options\n",
    "        self.advanced_checkbox = widgets.Checkbox(value=False, description=\"Advanced options\", style={'description_width': 'initial'})\n",
    "        self.preserve_geoms_checkbox = widgets.Checkbox(value=False, description=\"Preserve overlapping geometries\", disabled=False)\n",
    "        self.intersection_ratio_checkbox = widgets.Checkbox(value=False, description=\"Enricher has uniform grids\", disabled=False)\n",
    "        self.grid_area_text = widgets.FloatText(value=1e6, description=\"Grid area:\", disabled=True, layout=widgets.Layout(width=\"165px\"))\n",
    "        self.custom_predicate_checkbox = widgets.Checkbox(value=False, description=\"Custom ST_Relate predicate string:\", disabled=False, layout=Layout(width=\"500px\"))\n",
    "        self.custom_predicate_text = widgets.Text(value=\"2********\", disabled=True, layout=widgets.Layout(width=\"200px\"))\n",
    "        \n",
    "        self.go_button = widgets.Button(description=\"Go\", disabled=True, layout=widgets.Layout(margin=\"5px 0px\", width=\"100px\", border=\"2px solid black\"))\n",
    "        self.go_button.style.font_weight = 'bold'\n",
    "        \n",
    "        # Console output text box\n",
    "        self.console_output = widgets.Output(layout=widgets.Layout(width=\"100%\", height=\"200px\", border=\"1px solid black\"))\n",
    "        self.clear_console_button = widgets.Button(description=\"Clear\", layout=widgets.Layout(width='80px', border=\"2px solid black\"))\n",
    "        self.clear_console_button.style.font_weight = 'bold'\n",
    "\n",
    "        # Layout\n",
    "        self._setup_layout()\n",
    "        self._setup_event_handlers()\n",
    "\n",
    "    def _setup_layout(self):\n",
    "        # First line: Enrich <df1> with <df2>\n",
    "        df_selection_line = widgets.HBox([\n",
    "            widgets.HTML(value=\"<h2 style='display: inline; margin-right: 10px;'>Enrich </h2>\"),\n",
    "            self.df1_dropdown,\n",
    "            widgets.HTML(value=\"<h2 style='display: inline; margin-right: 10px;'> with </h2>\"),\n",
    "            self.df2_dropdown,\n",
    "            self.load_button\n",
    "        ])\n",
    "\n",
    "        # Second line: with attributes: <cols>\n",
    "        cols_selection_line = widgets.HBox([\n",
    "            widgets.HTML(value=\"<h2 style='display: inline; margin-right: 10px;'> with attributes: </h2>\"),\n",
    "            self.cols_dropdown,\n",
    "            self.agg_table_output,\n",
    "        ])\n",
    "\n",
    "        # Third line: unique id: <col>\n",
    "        grp_by_selection_line = widgets.HBox([\n",
    "            widgets.HTML(value=f\"<h2 style='display: inline; margin-right: 10px;'><span id='unique_id_text'>unique identifier:</span> </h2>\"),\n",
    "            self.group_by_dropdown,\n",
    "            self.go_button\n",
    "        ])\n",
    "\n",
    "        # Advanced options\n",
    "        self.advanced_options = widgets.VBox(\n",
    "            [\n",
    "                self.preserve_geoms_checkbox,\n",
    "                widgets.HBox([self.intersection_ratio_checkbox, self.grid_area_text]),\n",
    "                widgets.HBox([self.custom_predicate_checkbox, self.custom_predicate_text]),\n",
    "            ],\n",
    "            layout=widgets.Layout(max_width=\"600px\", display=\"none\")\n",
    "        )\n",
    "\n",
    "        # Main layout\n",
    "        self.main_layout = widgets.VBox([\n",
    "            self.heading,\n",
    "            widgets.HTML(value=\"<div style='height: 5px;'></div>\"),\n",
    "            df_selection_line,\n",
    "            self.load_status,\n",
    "            cols_selection_line,\n",
    "            widgets.HTML(value=\"<div style='height: 4px;'></div>\"),\n",
    "            grp_by_selection_line,\n",
    "            self.agg_status,\n",
    "            widgets.HTML(value=\"<div style='height: 3px;'></div>\"),\n",
    "            self.advanced_checkbox,\n",
    "            self.advanced_options,\n",
    "            widgets.HBox([self.console_output, self.clear_console_button])\n",
    "        ])\n",
    "\n",
    "        # Display everything\n",
    "        display(self.main_layout)\n",
    "\n",
    "    def _setup_event_handlers(self):\n",
    "        # Enable/disable load button based on dataframe selection\n",
    "        def on_df_selection_change(change):\n",
    "            if self.df1_dropdown.value and self.df2_dropdown.value:\n",
    "                self.load_button.disabled = False\n",
    "            else:\n",
    "                self.load_button.disabled = True\n",
    "        self.df1_dropdown.observe(on_df_selection_change, names='value')\n",
    "        self.df2_dropdown.observe(on_df_selection_change, names='value')\n",
    "\n",
    "        # Handle load button click\n",
    "        def on_load_button_click(b):\n",
    "            try:\n",
    "                df1_name = self.df1_dropdown.value\n",
    "                df2_name = self.df2_dropdown.value\n",
    "\n",
    "                if df1_name not in self.loaded_dataframes or df2_name not in self.loaded_dataframes:\n",
    "                    raise ValueError(\"Selected dataframes are not loaded in memory.\")\n",
    "\n",
    "                # Set the selected dataframes in the Enricher\n",
    "                self.enricher.df1 = self.loaded_dataframes[df1_name]\n",
    "                self.enricher.df2 = self.loaded_dataframes[df2_name]\n",
    "\n",
    "                # Update column dropdowns\n",
    "                self.cols_dropdown.options = self.loaded_dataframes[self.df2_dropdown.value].columns\n",
    "                self.group_by_dropdown.options = self.loaded_dataframes[self.df1_dropdown.value].columns\n",
    "                self.cols_dropdown.disabled = False\n",
    "                self.group_by_dropdown.disabled = False\n",
    "\n",
    "                self.load_status.value = f\"<small>Status: Loaded {df1_name} and {df2_name}.</small>\"\n",
    "                self.main_layout.children[6].children[0].value = f\"<h2 style='display: inline; margin-right: 10px;'>{df1_name}'s unique identifier: </h2>\"\n",
    "            except Exception as e:\n",
    "                self.load_status.value = f\"<small>Error: {str(e)}</small>\"\n",
    "\n",
    "        self.load_button.on_click(on_load_button_click)\n",
    "\n",
    "        # Handle column selection\n",
    "        def on_cols_change(change):\n",
    "            for col in change[\"new\"]:\n",
    "                if col not in self.selected_cols:\n",
    "                    self.selected_cols.append(col)\n",
    "            \n",
    "            self.cols_dropdown.options = [col for col in self.loaded_dataframes[self.df2_dropdown.value].columns if col not in self.selected_cols]\n",
    "            \n",
    "            # Preserve previously selected operations, default to \"sum\" for new columns\n",
    "            for col in self.selected_cols:\n",
    "                if col not in self.selected_aggs:\n",
    "                    self.selected_aggs[col] = \"sum\"            \n",
    "            \n",
    "            def generate_agg_table():\n",
    "                headers = [\"Selected Column\", \"Operation\", \"\"]\n",
    "                \n",
    "                cell_style = widgets.Layout(\n",
    "                    # border=\"1px solid black\", \n",
    "                    padding=\"0px 2px\",\n",
    "                    align_items=\"center\", \n",
    "                    justify_content=\"center\", \n",
    "                    width=\"125px\"\n",
    "                )\n",
    "                \n",
    "                clr_style = widgets.Layout(border=\"1px solid black\", padding=\"0px 2px\",align_items=\"center\", justify_content=\"center\", width=\"80px\")\n",
    "                \n",
    "                header_row = [\n",
    "                    widgets.HTML(f\"<b>{headers[0]}</b>\", layout=cell_style),\n",
    "                    widgets.HTML(f\"<b>{headers[1]}</b>\", layout=cell_style),\n",
    "                    widgets.HTML(\"\", layout=widgets.Layout(padding=\"0px 2px\",align_items=\"center\", justify_content=\"center\", width=\"80px\"))\n",
    "                ]\n",
    "            \n",
    "                rows = []\n",
    "                for col in self.selected_aggs:\n",
    "                    dropdown = widgets.Dropdown(\n",
    "                        options=self.agg_options, \n",
    "                        value=self.selected_aggs[col], \n",
    "                        layout=cell_style\n",
    "                    )\n",
    "                    dropdown.observe(lambda change, col=col: self.selected_aggs.update({col: change[\"new\"]}), names=\"value\")\n",
    "            \n",
    "                    clear_button = widgets.Button(description=\"Clear\", layout=clr_style)\n",
    "\n",
    "                    def on_clear(btn, col=col):\n",
    "                        self.selected_cols.remove(col)\n",
    "                        self.agg_status.value = f\"Status: Aggregating with: {', '.join([f'<b>{col}</b>' for col in self.selected_cols]) if self.selected_cols else '<i>select cols</i>'}, grouping by: {f'<b>{self.group_by_col}</b>' if self.group_by_col else '<i>select cols</i>'}\"\n",
    "                        del self.selected_aggs[col]\n",
    "                        self.cols_dropdown.options = [col for col in self.loaded_dataframes[self.df2_dropdown.value].columns if col not in self.selected_cols]\n",
    "                        \n",
    "                        with self.agg_table_output:\n",
    "                            self.agg_table_output.clear_output()\n",
    "                            display(generate_agg_table())\n",
    "                        \n",
    "                    clear_button.on_click(on_clear)\n",
    "                        \n",
    "                    rows.extend([\n",
    "                        widgets.HTML(col, layout=cell_style),\n",
    "                        dropdown,\n",
    "                        clear_button\n",
    "                    ])\n",
    "                \n",
    "                scrollable_container = widgets.VBox([\n",
    "                    widgets.GridBox(\n",
    "                        children=header_row + rows,\n",
    "                        layout=widgets.Layout(\n",
    "                            grid_template_columns=\"150px 150px 90px\",\n",
    "                            grid_template_rows=\"auto\",\n",
    "                            padding=\"1px\",\n",
    "                            width=\"max-content\",\n",
    "                        )\n",
    "                    )\n",
    "                ], layout=widgets.Layout(\n",
    "                    max_height=\"150px\",\n",
    "                    overflow_y=\"auto\",\n",
    "                    border=\"1px solid black\"\n",
    "                ))\n",
    "            \n",
    "                return scrollable_container\n",
    "\n",
    "\n",
    "            with self.agg_table_output:\n",
    "                self.agg_table_output.clear_output()\n",
    "                display(generate_agg_table())\n",
    "\n",
    "            self.agg_status.value = f\"Status: Will aggregate with: {', '.join([f'<b>{col}</b>' for col in self.selected_cols]) if self.selected_cols else '<i>select cols</i>'}; grouping by: {f'<b>{self.group_by_col}</b>' if self.group_by_col else '<i>select cols</i>'}\"\n",
    "            if self.group_by_col and self.selected_cols:\n",
    "                self.go_button.disabled = False            \n",
    "        self.cols_dropdown.observe(on_cols_change, names='value')\n",
    "\n",
    "        \n",
    "        def on_group_by_change(change):\n",
    "            self.group_by_col = change[\"new\"]\n",
    "            self.agg_status.value = f\"Status: Will aggregate with: {', '.join([f'<b>{col}</b>' for col in self.selected_cols]) if self.selected_cols else '<i>select col</i>'}; grouping by: {f'<b>{self.group_by_col}</b>' if self.group_by_col else '<i>select col</i>'}\"\n",
    "            if self.group_by_col and self.selected_cols:\n",
    "                self.go_button.disabled = False                \n",
    "                \n",
    "\n",
    "        self.group_by_dropdown.observe(on_group_by_change, names='value')\n",
    "\n",
    "\n",
    "        def on_advanced_checkbox_change(change):\n",
    "            if change[\"new\"]:\n",
    "                self.advanced_options.layout.display = \"block\"                \n",
    "\n",
    "            else:\n",
    "                self.advanced_options.layout.display = \"none\"\n",
    "\n",
    "        self.advanced_checkbox.observe(on_advanced_checkbox_change, names='value')\n",
    "\n",
    "        def on_intersection_ratio_change(change):\n",
    "            self.grid_area_text.disabled = not change[\"new\"]\n",
    "        self.intersection_ratio_checkbox.observe(on_intersection_ratio_change, names='value')\n",
    "\n",
    "        def on_custom_predicate_change(change):\n",
    "            self.custom_predicate_text.disabled = not change[\"new\"]\n",
    "        self.custom_predicate_checkbox.observe(on_custom_predicate_change, names='value')\n",
    "\n",
    "        def on_go_button_click(b):\n",
    "            with self.console_output:\n",
    "                try:\n",
    "                    print(\"Performing operation. This may take a while. Check logs for Spark logs and completion status.\")\n",
    "                    self.enricher.join_chey_new(\n",
    "                        selected_aggs=self.selected_aggs,\n",
    "                        df1_name=self.df1_dropdown.value,\n",
    "                        df2_name=self.df2_dropdown.value,\n",
    "                        group_by=self.group_by_col,\n",
    "                        pred=\"ST_Relate\" if self.custom_predicate_checkbox.value else \"ST_Intersects\",\n",
    "                        rel_str=self.custom_predicate_text.value if self.custom_predicate_checkbox.value else \"2********\",\n",
    "                        make_geom=True,\n",
    "                        ratio=self.intersection_ratio_checkbox.value,\n",
    "                        madre=self.preserve_geoms_checkbox.value,\n",
    "                        cache=True,\n",
    "                        grid_area=float(self.grid_area_text.value) if self.intersection_ratio_checkbox.value else 1e6\n",
    "                    )\n",
    "                    print(\"Enrichment operation completed.\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error: {str(e)}\")\n",
    "        \n",
    "        self.go_button.on_click(on_go_button_click)\n",
    "\n",
    "        def on_clear_console_button_click(b):\n",
    "            self.console_output.clear_output()\n",
    "        self.clear_console_button.on_click(on_clear_console_button_click)\n",
    "\n",
    "    def add_dataframe(self, name, dataframe):\n",
    "        self.loaded_dataframes[name] = dataframe\n",
    "        self.df1_dropdown.options = list(self.loaded_dataframes.keys())\n",
    "        self.df2_dropdown.options = list(self.loaded_dataframes.keys())\n",
    "        self.df1_dropdown.disabled = False\n",
    "        self.df2_dropdown.disabled = False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sedona initialized with 10 cores for parellelism.\n",
      "\n",
      "Loading datasets...\n",
      "Make sure the geometry column is named \"geometry\" in the datasets\n",
      "Loaded 'countries': (259, 12), 'EPSG:3035'\n",
      "Loaded 'regions': (20, 6), 'EPSG:32632'\n",
      "Loaded 'provinces': (107, 13), 'EPSG:32632'\n",
      "Loaded 'comuni_EU': (122750, 12), 'EPSG:3035'\n",
      "Loaded 'comuni': (7899, 13), 'EPSG:32632'\n",
      "in geoparquet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/homes_data/sudheer/benchmark_data/sedona_venv/lib/python3.12/site-packages/pyogrio/raw.py:198: RuntimeWarning: GPKG: unrecognized user_version=0x00000000 (0) on './data_EU/census_grid_EU/grids_new.gpkg'\n",
      "  return ogr_read(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 'pop_grids_new' from layer 'type': (7055226, 20), 'EPSG:3035'\n",
      "6 datasets loaded. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "# file paths:\n",
    "\n",
    "path_contr = \"./data_EU/countries_shp/\"\n",
    "path_reg = \"./data_Italy/regioni/\"\n",
    "path_prov = \"./data_Italy/provinci\"\n",
    "path_com_EU = \"./data_EU/comuni_shp/\"\n",
    "path_com = \"./data_Italy/comuni/\"\n",
    "path_grids = \"./data_EU/census_grid_EU/grids_corrected.parquet\"\n",
    "path_grids_new = \"./data_EU/census_grid_EU/grids_new.gpkg\"\n",
    "\n",
    "\n",
    "# datasets:\n",
    "# format: {display_name: (path, file_format), ...}\n",
    "\n",
    "datasets = {\n",
    "    \"countries\": (path_contr, \"shapefile\"),\n",
    "    \"regions\": (path_reg, \"shapefile\"),\n",
    "    \"provinces\": (path_prov, \"shapefile\"),\n",
    "    \"comuni_EU\": (path_com_EU, \"shapefile\"),\n",
    "    \"comuni\": (path_com, \"shapefile\"),\n",
    "    \"pop_grids\": (path_grids, \"geoparquet\"),\n",
    "    \"pop_grids_new\": (path_grids_new, \"geopackage\")\n",
    "    # \"census\": (path_census, \"\"),\n",
    "}\n",
    "\n",
    "\n",
    "obj = Enricher(crs=\"EPSG:3035\")\n",
    "obj.setup_cluster(which=\"sedona\", ex_mem=26, dr_mem=24, log_level=\"ERROR\")\n",
    "\n",
    "obj.load(datasets, silent=True)\n",
    "# obj.fix_geometries()\n",
    "# obj.force_repartition(skip=['pop_grids'])\n",
    "# obj.transform(lazy=False)\n",
    "\n",
    "# obj.inspect_partitions()\n",
    "\n",
    "# obj.dfs_list['comuni_EU'] = obj.dfs_list['comuni_EU'].filter(F.col('CNTR_ID').isin([\"IT\", \"DE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/contextlib.py:137: RuntimeWarning: GPKG: unrecognized user_version=0x00000000 (0) on './data_EU/census_grid_EU/grids_new.gpkg'\n",
      "  return next(self.gen)\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Path to your GeoPackage file\n",
    "gpkg_file = \"./data_EU/census_grid_EU/grids_new.gpkg\"\n",
    "\n",
    "# Path to the output GeoParquet file\n",
    "parquet_file = \"./data_EU/census_grid_EU/grids_new.parquet\"\n",
    "\n",
    "# Read the GeoPackage file\n",
    "gdf = gpd.read_file(f'{gpkg_file}', engine='pyogrio', use_arrow=True)\n",
    "\n",
    "print(gdf.columns)\n",
    "# # gdf = gdf.rename_geometry(\"geometry\")\n",
    "\n",
    "# # Convert the GeoDataFrame to a PyArrow Table\n",
    "# table = pa.Table.from_pandas(gdf)\n",
    "\n",
    "# # Write the table to a GeoParquet file\n",
    "# pq.write_table(table, parquet_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "for name, df in obj.dfs_list.items():\n",
    "    df.coalesce(1).rdd.saveAsPickleFile(f\"./pickles/dfs_list/{name}\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_df = obj.dfs_list['countries'].filter(F.col('CNTR_ID').isin([\"IT\", \"NL\", \"BE\", \"DE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc3ee3c6f0d4c23b8aca294416f708d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h1>Enrich with Overlay & Aggregation</h1>'), HTML(value=\"<div style='height: 5px;'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# GUI\n",
    "\n",
    "obj_ui = EnricherUI(obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "obj.res.columns\n",
    "# unique_values = obj.res.select('CNTR_ID').distinct().rdd.flatMap(lambda x: x).collect()\n",
    "# print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "temp = obj.res.drop(\"df1_geom\", \"intr_geometry\")\n",
    "print(temp.columns)\n",
    "temp.coalesce(1).write.mode(\"overwrite\").format(\"geoparquet\").save(f\"./outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Guide: https://docs.kepler.gl/docs/keplergl-jupyter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'df2_geom'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/benchmark_data/sedona_venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'df2_geom'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gdf\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mmap\u001b[39m \u001b[38;5;241m=\u001b[39m KeplerGl(height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m600\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28mmap\u001b[39m\u001b[38;5;241m.\u001b[39madd_data(data\u001b[38;5;241m=\u001b[39m\u001b[43mprep_for_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeom_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdf2_geom\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpop_grids\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mmap\u001b[39m\n",
      "Cell \u001b[0;32mIn[4], line 15\u001b[0m, in \u001b[0;36mprep_for_map\u001b[0;34m(res_agr, crs, geom_col)\u001b[0m\n\u001b[1;32m     13\u001b[0m df \u001b[38;5;241m=\u001b[39m res_agr\u001b[38;5;241m.\u001b[39mtoPandas()\n\u001b[1;32m     14\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mfloat\u001b[39m(x) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, decimal\u001b[38;5;241m.\u001b[39mDecimal) \u001b[38;5;28;01melse\u001b[39;00m x)\n\u001b[0;32m---> 15\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mgeom_col\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m geom: shape(geom))\n\u001b[1;32m     17\u001b[0m gdf \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mGeoDataFrame(df, geometry\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     18\u001b[0m gdf\u001b[38;5;241m.\u001b[39mcrs \u001b[38;5;241m=\u001b[39m crs\n",
      "File \u001b[0;32m~/benchmark_data/sedona_venv/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/benchmark_data/sedona_venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'df2_geom'"
     ]
    }
   ],
   "source": [
    "from keplergl import KeplerGl\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "import decimal\n",
    "\n",
    "# temp_df = obj.res_agr\n",
    "# temp_df = obj.res.filter(F.col('CNTR_ID').isin(\"NL\", \"BE\", \"DE\", \"IT\"))\n",
    "# temp_df = obj.dfs_list['comuni_EU']\n",
    "temp_df = obj.dfs_list['pop_grids'].filter(F.col('T')>1000)\n",
    "\n",
    "\n",
    "def prep_for_map(res_agr, crs, geom_col=\"geometry\"):\n",
    "    df = res_agr.toPandas()\n",
    "    df = df.map(lambda x: float(x) if isinstance(x, decimal.Decimal) else x)\n",
    "    df['geometry'] = df[f'{geom_col}'].apply(lambda geom: shape(geom))\n",
    "\n",
    "    gdf = gpd.GeoDataFrame(df, geometry='geometry')\n",
    "    gdf.crs = crs\n",
    "    \n",
    "    return gdf\n",
    "\n",
    "map = KeplerGl(height=600)\n",
    "map.add_data(data=prep_for_map(temp_df, obj.crs, geom_col=\"df2_geom\"), name=\"pop_grids\")\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keplergl import KeplerGl\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "import decimal\n",
    "\n",
    "res_agr = obj.res_agr\n",
    "\n",
    "# res_agr = obj.dfs_list['provinces']\n",
    "\n",
    "df = res_agr.toPandas()\n",
    "df = df.map(lambda x: float(x) if isinstance(x, decimal.Decimal) else x)\n",
    "df['geometry'] = df['geometry'].apply(lambda geom: shape(geom))\n",
    "\n",
    "gdf = gpd.GeoDataFrame(df, geometry='geometry')\n",
    "# gdf.crs = \"EPSG:3035\"\n",
    "gdf.crs = obj.crs\n",
    "\n",
    "map = KeplerGl(height=600)\n",
    "map.add_data(data=gdf, name=\"df\")\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_EU_com_enriched = obj.res_agr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Guide: https://docs.kepler.gl/docs/keplergl-jupyter\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a537a4fb6604e8fab471ca6fb390dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "KeplerGl(data={'res_agr': {'index': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,…"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keplergl import KeplerGl\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "\n",
    "com_pop = obj.res_agr\n",
    "\n",
    "res_agr = com_pop.toPandas()\n",
    "res_agr['geometry'] = res_agr['geometry'].apply(lambda geom: shape(geom))\n",
    "\n",
    "gdf = gpd.GeoDataFrame(res_agr, geometry='geometry')\n",
    "gdf.crs = \"EPSG:3035\"\n",
    "\n",
    "map = KeplerGl(height=600)\n",
    "map.add_data(data=gdf, name=\"res_agr\")\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sedona_venv)",
   "language": "python",
   "name": "sedona_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
