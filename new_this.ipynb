{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sedona.spark import *\n",
    "from contextlib import contextmanager\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "from pyspark.sql import DataFrame\n",
    "# from pyspark.sql.functions import *\n",
    "from pyspark.sql import functions as F\n",
    "# from pyspark.sql.functions import col, first, expr\n",
    "import time\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import sys\n",
    "import io\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Button, Layout\n",
    "from IPython.display import *\n",
    "from io import StringIO\n",
    "import sys\n",
    "\n",
    "\n",
    "class Enricher:\n",
    "\n",
    "    def __init__(self, crs=\"EPSG:3035\"):\n",
    "        self.crs = crs if type(crs) is not int else f\"EPSG:{crs}\"\n",
    "        self.cores = None\n",
    "        self.res = None\n",
    "        self.sedona = None\n",
    "        self.res_agr = None\n",
    "        self.df1 = None\n",
    "        self.df2 = None\n",
    "        self.force_repartition = False\n",
    "        self.dfs_list = {}\n",
    "\n",
    "            \n",
    "    def setup_cluster(self, which=\"wherobots\", ex_mem=26, dr_mem=24, log_level=None):\n",
    "        if which == \"wherobots\":\n",
    "            config = SedonaContext.builder().getOrCreate()\n",
    "            self.sedona = SedonaContext.create(config)\n",
    "            \n",
    "            self.cores = self.sedona.sparkContext.defaultParallelism\n",
    "            print(f\"Wherobots setup started with {self.cores} cores for parellelism.\")\n",
    "        elif which == \"sedona\":\n",
    "            # config = SedonaContext.builder() .\\\n",
    "            #     config(\"spark.executor.memory\", f\"{ex_mem}g\").\\\n",
    "            #     config(\"spark.driver.memory\", f\"{dr_mem}g\").\\\n",
    "            #     config('spark.jars.packages',\\\n",
    "            #         'org.apache.sedona:sedona-spark-shaded-3.5_2.12:1.7.0,'\\\n",
    "            #         'org.datasyslab:geotools-wrapper:1.7.0-28.5').\\\n",
    "            #     getOrCreate()\n",
    "\n",
    "            config = SedonaContext.builder() \\\n",
    "                .config(\"spark.executor.memory\", f\"{ex_mem}g\") \\\n",
    "                .config(\"spark.driver.memory\", f\"{dr_mem}g\") \\\n",
    "                .config(\"spark.local.dir\", \"./tmp_spark_spills\") \\\n",
    "                .config('spark.jars.packages',\n",
    "                    'org.apache.sedona:sedona-spark-shaded-3.5_2.12:1.7.0,'\n",
    "                    'org.datasyslab:geotools-wrapper:1.7.0-28.5') \\\n",
    "                .getOrCreate()\n",
    "\n",
    "\n",
    "            self.sedona = SedonaContext.create(config)\n",
    "            \n",
    "            if log_level in [\"OFF\", \"ERROR\", \"WARN\", \"INFO\", \"DEBUG\"]:\n",
    "                self.sedona.sparkContext.setLogLevel(log_level)\n",
    "                \n",
    "            self.cores = self.sedona.sparkContext.defaultParallelism\n",
    "            print(f\"Sedona initialized with {self.cores} cores for parellelism.\")\n",
    "        else:\n",
    "            raise ValueError(\"Invalid 'which'. Choose either 'wherobots' or 'sedona'\")\n",
    "        \n",
    "    @contextmanager\n",
    "    def get_time(self, task_name):\n",
    "        start = time.time()\n",
    "        yield\n",
    "        elapsed = time.time() - start\n",
    "    \n",
    "        print(f\"{task_name}... DONE in {(elapsed/60):.2f} min\" \\\n",
    "              if elapsed >= 60 else f\"{task_name}... DONE in {elapsed:.2f} sec\")\n",
    "\n",
    "    \n",
    "    def load(self, datasets, silent=True, force_repartition=False):\n",
    "        print(\"\\nLoading datasets...\")\n",
    "        print(f\"Make sure the geometry column is named \\\"geometry\\\" in the datasets\")\n",
    "    \n",
    "        self.datasets = {}\n",
    "        for name, (path, fformat) in datasets.items():\n",
    "            if fformat != \"geoparquet\":\n",
    "                gdf = gpd.read_file(path)\n",
    "                crs = gdf.crs\n",
    "            else:\n",
    "                gdf = gpd.read_parquet(path)\n",
    "                crs = f\"EPSG:{gdf.crs.to_epsg()}\"\n",
    "            \n",
    "            if format != \"geopackage\":\n",
    "                self.dfs_list[name] = self.sedona.read.format(fformat).load(path)\n",
    "            else:\n",
    "                self.dfs_list[name] = self.sedona.read.format(fformat).option(\"showMetadata\", \"true\").load(path)\n",
    "            \n",
    "            print(f\"Loaded '{name}': {gdf.shape}, '{crs}'\")\n",
    "            self.datasets[name] = (path, fformat, crs)\n",
    "\n",
    "        \n",
    "        \n",
    "        if force_repartition:\n",
    "            self.force_repartition = True\n",
    "            for df in self.dfs_list.values():\n",
    "                df = df.repartition(self.cores)\n",
    "            \n",
    "        print(f\"{len(self.dfs_list)} datasets loaded. \\n\")\n",
    "        \n",
    "        if not silent:\n",
    "            for name, df in self.dfs_list.items():\n",
    "                print(f\"\\n Dataset: \\\"{name}\\\", count: {df.count()}\")\n",
    "    \n",
    "                geometry_types = df.select(F.expr(\"ST_GeometryType(geometry)\")).distinct().collect()\n",
    "                \n",
    "                res_string = [\n",
    "                    f\"{geometry_type} ({(df.filter(F.expr(f'ST_GeometryType(geometry) = \\'{geometry_type}\\'')).count() / df.count()) * 100:.2f}%)\"\n",
    "                    for row in geometry_types if (geometry_type := row[0])\n",
    "                ]\n",
    "                \n",
    "                print(f\"\\\"{name}\\\" has geometries of type(s): {', '.join(res_string)}\")\n",
    "                df.printSchema()\n",
    "\n",
    "    def audit_partitions(self):\n",
    "        for name, df in self.dfs_list.items():\n",
    "            print(f\"'{name}' partitions: {df.rdd.getNumPartitions()}\")\n",
    "            print(f\"'{name}' distribution: {df.rdd.glom().map(len).collect()}\")\n",
    "\n",
    "    \n",
    "    def transform(self, target=None, lazy=True):\n",
    "        if target is None:\n",
    "            target = self.crs\n",
    "        elif type(target) is int:\n",
    "            self.crs = f\"EPSG:{target}\"\n",
    "            target = self.crs\n",
    "        else:\n",
    "            self.crs = target\n",
    "        \n",
    "        print()\n",
    "        print(\"Transforming CRS...\")\n",
    "        for name, df in self.dfs_list.items():\n",
    "            df = df.withColumn(\"geometry\", F.expr(f\"ST_Transform(geometry, '{self.datasets[name][2]}', '{target}')\"))\n",
    "            print(f\"Changed CRS of '{name}': '{self.datasets[name][2]}' to '{target}'\")\n",
    "            self.dfs_list[name] = df\n",
    "            \n",
    "            if not lazy:\n",
    "                self.dfs_list[name].cache()\n",
    "            \n",
    "    def fix_geometries(self):\n",
    "\n",
    "        for name, df in self.dfs_list.items():\n",
    "\n",
    "            invalid_count = df.filter(F.expr(\"NOT ST_IsValid(geometry)\")).count()\n",
    "            \n",
    "            print(f\"'{name}' has {((invalid_count / df.count()) * 100 if df.count() > 0 else 0):.2f}% invalid geometries.\")\n",
    "            \n",
    "            if invalid_count > 0:\n",
    "                df = df.withColumn(\"geometry\", F.expr(\"ST_MakeValid(geometry)\"))\n",
    "                print(f\"Fixed {invalid_count} geometries in '{name}'\")\n",
    "            else:\n",
    "                print(f\"Nothing to fix in '{name}'\")\n",
    "            \n",
    "            self.dfs_list[name] = df\n",
    "\n",
    "    \n",
    "    def _make_cache(self, df):\n",
    "        # cached_dfs = []\n",
    "        if isinstance(df, DataFrame):\n",
    "            \n",
    "            if df.storageLevel != StorageLevel.NONE:\n",
    "                df.unpersist()\n",
    "            df.cache()\n",
    "            print(f\"Dataset cached. {df.count()} rows.\")\n",
    "            # cached_dfs.append(df)\n",
    "        # return cached_dfs\n",
    "    \n",
    "    def clear_memory(self, *keep):\n",
    "        if self.res.storageLevel != StorageLevel.NONE:\n",
    "            self.res.unpersist()\n",
    "        self.res = None\n",
    "\n",
    "    def join_chey_new(self, selected_aggs, df1_name, df2_name, group_by=None, pred=\"ST_Intersects\", rel_str=\"2********\", make_geom=True, ratio=True, madre=False, cache=True, grid_area=None):\n",
    "        \n",
    "        # self.df1 = self.dfs_list[df1_name]\n",
    "        # self.df2 = self.dfs_list[df2_name]\n",
    "    \n",
    "        \n",
    "        join_expr = f\"{pred}(df1.geometry, df2.geometry)\"\n",
    "        if pred == \"ST_Relate\":\n",
    "            join_expr = f\"{pred}(df1.geometry, df2.geometry, '{rel_str}')\"\n",
    "    \n",
    "        self.res = self.dfs_list[df1_name].alias(\"df1\").join(\n",
    "            self.dfs_list[df2_name].alias(\"df2\"), F.expr(join_expr)\n",
    "        ).select(\n",
    "            F.expr(\"df1.geometry\").alias(\"df1_geom\"),\n",
    "            F.expr(\"df2.geometry\").alias(\"df2_geom\"),\n",
    "            *[f\"df1.{c}\" for c in self.dfs_list[df1_name].columns if c != \"geometry\"],\n",
    "            *[f\"df2.{c}\" for c in self.dfs_list[df2_name].columns if c != \"geometry\" and c not in self.dfs_list[df1_name].columns]\n",
    "        )\n",
    "\n",
    "        # print(f\"Join operation completed. {self.res.count()} rows.\")\n",
    "        \n",
    "        self.res = self.res.withColumn(\"intr_geometry\", F.expr(\"ST_Intersection(df1_geom, df2_geom)\"))\n",
    "        if ratio:\n",
    "            if grid_area > 0:\n",
    "                self.res = self.res.withColumn(\"intr_ratio\", F.expr(f\"ST_Area(intr_geometry) / {grid_area}\"))\n",
    "            else:\n",
    "                self.res = self.res.withColumn(\"intr_ratio\", F.expr(\"ST_Area(intr_geometry) / ST_Area(df2_geom)\"))\n",
    "\n",
    "            agg_exprs = []\n",
    "            for col_name, agg_func in selected_aggs.items():\n",
    "                if agg_func == \"sum\":\n",
    "                    temp = F.sum(F.col(col_name) * F.col(\"intr_ratio\")).alias(f\"{col_name}_agr\")\n",
    "                    agg_exprs.append(temp)\n",
    "                elif agg_func == \"mean\":\n",
    "                    agg_exprs.append(F.mean(F.col(col_name) * F.col(\"intr_ratio\")).alias(f\"{col_name}_agr\"))\n",
    "                elif agg_func == \"min\":\n",
    "                    agg_exprs.append(F.min(F.col(col_name) * F.col(\"intr_ratio\")).alias(f\"{col_name}_agr\"))\n",
    "                elif agg_func == \"max\":\n",
    "                    agg_exprs.append(F.max(F.col(col_name) * F.col(\"intr_ratio\")).alias(f\"{col_name}_agr\"))\n",
    "                elif agg_func == \"count\":\n",
    "                    agg_exprs.append(F.count(F.col(col_name)).alias(f\"{col_name}_agr\"))\n",
    "                else:\n",
    "                    raise ValueError(f\"Unsupported aggregation function: {agg_func}\")\n",
    "                \n",
    "            df1_cols = [F.first(F.col(f\"df1.{c}\")).alias(c) for c in self.dfs_list[df1_name].columns if c != group_by and c != \"geometry\"]\n",
    "            df1_cols.append(F.first(F.col(\"df1_geom\")).alias(\"geometry\"))\n",
    "            self.res_agr = self.res.groupBy(group_by).agg(*df1_cols, *agg_exprs)\n",
    "\n",
    "            print(f\"Aggregation completed. {self.res_agr.count()} rows.\")\n",
    "            \n",
    "            if madre:\n",
    "                columns_to_drop = [\"df1_geom\", \"df2_geom\"] + list(selected_aggs.keys())\n",
    "                self.res = self.res.drop(*columns_to_drop)\n",
    "                self.res = self.res.join(self.res_agr.drop(\"geometry\"), on=group_by, how=\"left\")\n",
    "                self.res = self.res.withColumnRenamed(\"intr_geometry\", \"geometry\")\n",
    "    \n",
    "        if cache:\n",
    "            if madre:\n",
    "                self.res.cache()\n",
    "                self.res.count()\n",
    "            self.res_agr.cache()\n",
    "            self.res_agr.count()\n",
    "            \n",
    "    \n",
    "        return self.res_agr\n",
    "    \n",
    "    \n",
    "\n",
    "    def export(self, df=\"default\", path=\"outputs\", name=\"unnamed\", how=\"repartition\", num=None, clear=False):\n",
    "        if num is None:\n",
    "            num = self.cores\n",
    "        if how == \"repartition\":\n",
    "            self.res = self.res.repartition(num)\n",
    "        elif how == \"coalesce\":\n",
    "            self.res = self.res.coalesce(num)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid 'how'. Choose either 'repartition' or 'coalesce'\")\n",
    "\n",
    "        if df == \"default\":\n",
    "            self.res_agr.write.mode(\"overwrite\").format(\"geoparquet\").save(f\"./{path}/\" + f\"/{name}_agr\")\n",
    "        else:\n",
    "            self.res.write.mode(\"overwrite\").format(\"geoparquet\").save(f\"./{path}/\" + f\"/{name}_madre\")\n",
    "        \n",
    "        if clear:\n",
    "            self.clear_memory()\n",
    "\n",
    "\n",
    "\n",
    "class EnricherUI:\n",
    "    def __init__(self, enricher):\n",
    "        self.enricher = enricher\n",
    "        self.loaded_dataframes = {}\n",
    "        self.selected_cols = []\n",
    "        self.group_by_col = None\n",
    "        self._init_ui()\n",
    "        self.loaded_dataframes = self.list_dataframes_in_memory()\n",
    "        self.df1_dropdown.options = list(self.loaded_dataframes.keys())\n",
    "        self.df2_dropdown.options = list(self.loaded_dataframes.keys())\n",
    "        self.df1_dropdown.disabled = False\n",
    "        self.df2_dropdown.disabled = False        \n",
    "        self.selected_aggs = {}\n",
    "        self.agg_options = [\"sum\", \"count\", \"mean\", \"min\", \"max\"]\n",
    "\n",
    "    def list_dataframes_in_memory(self):\n",
    "        # return {name: obj for name, obj in globals().items() if isinstance(obj, pd.DataFrame)}\n",
    "        return {name: df for name, df in self.enricher.dfs_list.items()}\n",
    "    \n",
    "    def _init_ui(self):\n",
    "        # Heading:\n",
    "        self.heading = widgets.HTML(value=\"<h1>Enrich with Overlay</h1>\")\n",
    "\n",
    "        # First line: Enrich <df1> with <df2>\n",
    "        self.df1_dropdown = widgets.Dropdown(options=[], description=\"df1:\", disabled=True, style={'description_width': 'initial'}, layout=widgets.Layout(margin=\"5px 20px\", width=\"150px\"))\n",
    "        self.df2_dropdown = widgets.Dropdown(options=[], description=\"df2:\", disabled=True, style={'description_width': 'initial'}, layout=widgets.Layout(margin=\"5px 20px\", width=\"150px\"))\n",
    "        self.load_status = widgets.HTML(value=\"<small>Status: No dataframes loaded.</small>\")\n",
    "        self.load_button = widgets.Button(description=\"Load\", disabled=True, layout=widgets.Layout(margin=\"5px 0px\", width=\"100px\", border=\"2px solid black\"))\n",
    "        self.load_button.style.font_weight = 'bold'\n",
    "\n",
    "        # Second line: with attributes: <cols>\n",
    "        self.cols_dropdown = widgets.SelectMultiple(options=[], description=\"aggr cols:\", disabled=True, style={'description_width': 'initial'})\n",
    "        self.agg_table_output = widgets.Output()        \n",
    "        \n",
    "        # Third line: unique id: <col>\n",
    "        self.group_by_dropdown = widgets.Dropdown(options=[], description=\"unique id:\", disabled=True, style={'description_width': 'initial'}, layout=widgets.Layout(margin=\"5px 20px\", width=\"250px\"))\n",
    "        \n",
    "        self.agg_status = widgets.HTML(value=\"\")\n",
    "\n",
    "        # Advanced options\n",
    "        self.advanced_checkbox = widgets.Checkbox(value=False, description=\"Advanced options\", style={'description_width': 'initial'})\n",
    "        self.preserve_geoms_checkbox = widgets.Checkbox(value=False, description=\"Preserve overlapping geometries\", disabled=False)\n",
    "        self.intersection_ratio_checkbox = widgets.Checkbox(value=False, description=\"Enricher has uniform grids\", disabled=False)\n",
    "        self.grid_area_text = widgets.FloatText(value=1e6, description=\"Grid area:\", disabled=True, layout=widgets.Layout(width=\"165px\"))\n",
    "        self.custom_predicate_checkbox = widgets.Checkbox(value=False, description=\"Custom ST_Relate predicate string:\", disabled=False, layout=Layout(width=\"500px\"))\n",
    "        self.custom_predicate_text = widgets.Text(value=\"2********\", disabled=True, layout=widgets.Layout(width=\"200px\"))\n",
    "        \n",
    "        self.go_button = widgets.Button(description=\"Go\", disabled=True, layout=widgets.Layout(margin=\"5px 0px\", width=\"100px\", border=\"2px solid black\"))\n",
    "        self.go_button.style.font_weight = 'bold'\n",
    "        \n",
    "        # Console output text box\n",
    "        self.console_output = widgets.Output(layout=widgets.Layout(width=\"100%\", height=\"200px\", border=\"1px solid black\"))\n",
    "        self.clear_console_button = widgets.Button(description=\"Clear\", layout=widgets.Layout(width='80px', border=\"2px solid black\"))\n",
    "        self.clear_console_button.style.font_weight = 'bold'\n",
    "\n",
    "        # Layout\n",
    "        self._setup_layout()\n",
    "        self._setup_event_handlers()\n",
    "\n",
    "    def _setup_layout(self):\n",
    "        # First line: Enrich <df1> with <df2>\n",
    "        df_selection_line = widgets.HBox([\n",
    "            widgets.HTML(value=\"<h2 style='display: inline; margin-right: 10px;'>Enrich </h2>\"),\n",
    "            self.df1_dropdown,\n",
    "            widgets.HTML(value=\"<h2 style='display: inline; margin-right: 10px;'> with </h2>\"),\n",
    "            self.df2_dropdown,\n",
    "            self.load_button\n",
    "        ])\n",
    "\n",
    "        # Second line: with attributes: <cols>\n",
    "        cols_selection_line = widgets.HBox([\n",
    "            widgets.HTML(value=\"<h2 style='display: inline; margin-right: 10px;'> with attributes: </h2>\"),\n",
    "            self.cols_dropdown,\n",
    "            self.agg_table_output,\n",
    "        ])\n",
    "\n",
    "        # Third line: unique id: <col>\n",
    "        grp_by_selection_line = widgets.HBox([\n",
    "            widgets.HTML(value=f\"<h2 style='display: inline; margin-right: 10px;'><span id='unique_id_text'>unique identifier:</span> </h2>\"),\n",
    "            self.group_by_dropdown,\n",
    "            self.go_button\n",
    "        ])\n",
    "\n",
    "        # Advanced options\n",
    "        self.advanced_options = widgets.VBox(\n",
    "            [\n",
    "                self.preserve_geoms_checkbox,\n",
    "                widgets.HBox([self.intersection_ratio_checkbox, self.grid_area_text]),\n",
    "                widgets.HBox([self.custom_predicate_checkbox, self.custom_predicate_text]),\n",
    "            ],\n",
    "            layout=widgets.Layout(max_width=\"600px\", display=\"none\")\n",
    "        )\n",
    "\n",
    "        # Main layout\n",
    "        self.main_layout = widgets.VBox([\n",
    "            self.heading,\n",
    "            widgets.HTML(value=\"<div style='height: 5px;'></div>\"),\n",
    "            df_selection_line,\n",
    "            self.load_status,\n",
    "            cols_selection_line,\n",
    "            widgets.HTML(value=\"<div style='height: 4px;'></div>\"),\n",
    "            grp_by_selection_line,\n",
    "            self.agg_status,\n",
    "            widgets.HTML(value=\"<div style='height: 3px;'></div>\"),\n",
    "            self.advanced_checkbox,\n",
    "            self.advanced_options,\n",
    "            widgets.HBox([self.console_output, self.clear_console_button])\n",
    "        ])\n",
    "\n",
    "        # Display everything\n",
    "        display(self.main_layout)\n",
    "\n",
    "    def _setup_event_handlers(self):\n",
    "        # Enable/disable load button based on dataframe selection\n",
    "        def on_df_selection_change(change):\n",
    "            if self.df1_dropdown.value and self.df2_dropdown.value:\n",
    "                self.load_button.disabled = False\n",
    "            else:\n",
    "                self.load_button.disabled = True\n",
    "        self.df1_dropdown.observe(on_df_selection_change, names='value')\n",
    "        self.df2_dropdown.observe(on_df_selection_change, names='value')\n",
    "\n",
    "        # Handle load button click\n",
    "        def on_load_button_click(b):\n",
    "            try:\n",
    "                df1_name = self.df1_dropdown.value\n",
    "                df2_name = self.df2_dropdown.value\n",
    "\n",
    "                if df1_name not in self.loaded_dataframes or df2_name not in self.loaded_dataframes:\n",
    "                    raise ValueError(\"Selected dataframes are not loaded in memory.\")\n",
    "\n",
    "                # Set the selected dataframes in the Enricher\n",
    "                self.enricher.df1 = self.loaded_dataframes[df1_name]\n",
    "                self.enricher.df2 = self.loaded_dataframes[df2_name]\n",
    "\n",
    "                # Update column dropdowns\n",
    "                self.cols_dropdown.options = self.loaded_dataframes[self.df2_dropdown.value].columns\n",
    "                self.group_by_dropdown.options = self.loaded_dataframes[self.df1_dropdown.value].columns\n",
    "                self.cols_dropdown.disabled = False\n",
    "                self.group_by_dropdown.disabled = False\n",
    "\n",
    "                self.load_status.value = f\"<small>Status: Loaded {df1_name} and {df2_name}.</small>\"\n",
    "                self.main_layout.children[6].children[0].value = f\"<h2 style='display: inline; margin-right: 10px;'>{df1_name}'s unique identifier: </h2>\"\n",
    "            except Exception as e:\n",
    "                self.load_status.value = f\"<small>Error: {str(e)}</small>\"\n",
    "\n",
    "        self.load_button.on_click(on_load_button_click)\n",
    "\n",
    "        # Handle column selection\n",
    "        def on_cols_change(change):\n",
    "            for col in change[\"new\"]:\n",
    "                if col not in self.selected_cols:\n",
    "                    self.selected_cols.append(col)\n",
    "            \n",
    "            self.cols_dropdown.options = [col for col in self.loaded_dataframes[self.df2_dropdown.value].columns if col not in self.selected_cols]\n",
    "            \n",
    "            # Preserve previously selected operations, default to \"sum\" for new columns\n",
    "            for col in self.selected_cols:\n",
    "                if col not in self.selected_aggs:\n",
    "                    self.selected_aggs[col] = \"sum\"            \n",
    "            \n",
    "            def generate_agg_table():\n",
    "                headers = [\"Column\", \"Operation\", \"\"]\n",
    "                \n",
    "                cell_style = widgets.Layout(\n",
    "                    # border=\"1px solid black\", \n",
    "                    padding=\"0px 2px\",\n",
    "                    align_items=\"center\", \n",
    "                    justify_content=\"center\", \n",
    "                    width=\"125px\"\n",
    "                )\n",
    "                \n",
    "                clr_style = widgets.Layout(border=\"1px solid black\", padding=\"0px 2px\",align_items=\"center\", justify_content=\"center\", width=\"80px\")\n",
    "                \n",
    "                header_row = [\n",
    "                    widgets.HTML(f\"<b>{headers[0]}</b>\", layout=cell_style),\n",
    "                    widgets.HTML(f\"<b>{headers[1]}</b>\", layout=cell_style),\n",
    "                    widgets.HTML(\"\", layout=widgets.Layout(padding=\"0px 2px\",align_items=\"center\", justify_content=\"center\", width=\"80px\"))\n",
    "                ]\n",
    "            \n",
    "                rows = []\n",
    "                for col in self.selected_aggs:\n",
    "                    dropdown = widgets.Dropdown(\n",
    "                        options=self.agg_options, \n",
    "                        value=self.selected_aggs[col], \n",
    "                        layout=cell_style\n",
    "                    )\n",
    "                    dropdown.observe(lambda change, col=col: self.selected_aggs.update({col: change[\"new\"]}), names=\"value\")\n",
    "            \n",
    "                    clear_button = widgets.Button(description=\"Clear\", layout=clr_style)\n",
    "\n",
    "                    def on_clear(btn, col=col):\n",
    "                        self.selected_cols.remove(col)\n",
    "                        self.agg_status.value = f\"Status: Aggregating with: {', '.join([f'<b>{col}</b>' for col in self.selected_cols]) if self.selected_cols else '<i>select cols</i>'}, grouping by: {f'<b>{self.group_by_col}</b>' if self.group_by_col else '<i>select cols</i>'}\"\n",
    "                        del self.selected_aggs[col]\n",
    "                        self.cols_dropdown.options = [col for col in self.loaded_dataframes[self.df2_dropdown.value].columns if col not in self.selected_cols]\n",
    "                        \n",
    "                        with self.agg_table_output:\n",
    "                            self.agg_table_output.clear_output()\n",
    "                            display(generate_agg_table())\n",
    "                        \n",
    "                    clear_button.on_click(on_clear)\n",
    "                        \n",
    "                    rows.extend([\n",
    "                        widgets.HTML(col, layout=cell_style),\n",
    "                        dropdown,\n",
    "                        clear_button\n",
    "                    ])\n",
    "                \n",
    "                scrollable_container = widgets.VBox([\n",
    "                    widgets.GridBox(\n",
    "                        children=header_row + rows,\n",
    "                        layout=widgets.Layout(\n",
    "                            grid_template_columns=\"150px 150px 90px\",\n",
    "                            grid_template_rows=\"auto\",\n",
    "                            padding=\"1px\",\n",
    "                            width=\"max-content\",\n",
    "                        )\n",
    "                    )\n",
    "                ], layout=widgets.Layout(\n",
    "                    max_height=\"150px\",\n",
    "                    overflow_y=\"auto\",\n",
    "                    border=\"1px solid black\"\n",
    "                ))\n",
    "            \n",
    "                return scrollable_container\n",
    "\n",
    "\n",
    "            with self.agg_table_output:\n",
    "                self.agg_table_output.clear_output()\n",
    "                display(generate_agg_table())\n",
    "\n",
    "            self.agg_status.value = f\"Status: Will aggregate with: {', '.join([f'<b>{col}</b>' for col in self.selected_cols]) if self.selected_cols else '<i>select cols</i>'}; grouping by: {f'<b>{self.group_by_col}</b>' if self.group_by_col else '<i>select cols</i>'}\"\n",
    "            if self.group_by_col and self.selected_cols:\n",
    "                self.go_button.disabled = False            \n",
    "        self.cols_dropdown.observe(on_cols_change, names='value')\n",
    "\n",
    "        \n",
    "        def on_group_by_change(change):\n",
    "            self.group_by_col = change[\"new\"]\n",
    "            self.agg_status.value = f\"Status: Will aggregate with: {', '.join([f'<b>{col}</b>' for col in self.selected_cols]) if self.selected_cols else '<i>select col</i>'}; grouping by: {f'<b>{self.group_by_col}</b>' if self.group_by_col else '<i>select col</i>'}\"\n",
    "            if self.group_by_col and self.selected_cols:\n",
    "                self.go_button.disabled = False                \n",
    "                \n",
    "\n",
    "        self.group_by_dropdown.observe(on_group_by_change, names='value')\n",
    "\n",
    "\n",
    "        def on_advanced_checkbox_change(change):\n",
    "            if change[\"new\"]:\n",
    "                self.advanced_options.layout.display = \"block\"                \n",
    "\n",
    "            else:\n",
    "                self.advanced_options.layout.display = \"none\"\n",
    "\n",
    "        self.advanced_checkbox.observe(on_advanced_checkbox_change, names='value')\n",
    "\n",
    "        def on_intersection_ratio_change(change):\n",
    "            self.grid_area_text.disabled = not change[\"new\"]\n",
    "        self.intersection_ratio_checkbox.observe(on_intersection_ratio_change, names='value')\n",
    "\n",
    "        def on_custom_predicate_change(change):\n",
    "            self.custom_predicate_text.disabled = not change[\"new\"]\n",
    "        self.custom_predicate_checkbox.observe(on_custom_predicate_change, names='value')\n",
    "\n",
    "        def on_go_button_click(b):\n",
    "            with self.console_output:\n",
    "                try:\n",
    "                    print(\"Performing operation. This may take a while. Check logs for Spark logs and completion status.\")\n",
    "                    self.enricher.join_chey_new(\n",
    "                        selected_aggs=self.selected_aggs,\n",
    "                        df1_name=self.df1_dropdown.value,\n",
    "                        df2_name=self.df2_dropdown.value,\n",
    "                        group_by=self.group_by_col,\n",
    "                        pred=\"ST_Relate\" if self.custom_predicate_checkbox.value else \"ST_Intersects\",\n",
    "                        rel_str=self.custom_predicate_text.value if self.custom_predicate_checkbox.value else \"2********\",\n",
    "                        make_geom=True,\n",
    "                        ratio=self.intersection_ratio_checkbox.value,\n",
    "                        madre=self.preserve_geoms_checkbox.value,\n",
    "                        cache=True,\n",
    "                        grid_area=float(self.grid_area_text.value) if self.intersection_ratio_checkbox.value else 1e6\n",
    "                    )\n",
    "                    print(\"Enrichment operation completed.\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error: {str(e)}\")\n",
    "        \n",
    "        self.go_button.on_click(on_go_button_click)\n",
    "\n",
    "        def on_clear_console_button_click(b):\n",
    "            self.console_output.clear_output()\n",
    "        self.clear_console_button.on_click(on_clear_console_button_click)\n",
    "\n",
    "    def add_dataframe(self, name, dataframe):\n",
    "        self.loaded_dataframes[name] = dataframe\n",
    "        self.df1_dropdown.options = list(self.loaded_dataframes.keys())\n",
    "        self.df2_dropdown.options = list(self.loaded_dataframes.keys())\n",
    "        self.df1_dropdown.disabled = False\n",
    "        self.df2_dropdown.disabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 78:===================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partitions: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 80:===================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distribution: [459403, 459403, 459401, 459400, 459400, 459400, 459402, 459402, 459403, 459404]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sedona initialized with 10 cores for parellelism.\n",
      "\n",
      "Loading datasets...\n",
      "Make sure the geometry column is named \"geometry\" in the datasets\n",
      "Loaded 'countries': (259, 12), 'EPSG:3035'\n",
      "Loaded 'regions': (20, 6), 'EPSG:32632'\n",
      "Loaded 'provinces': (107, 13), 'EPSG:32632'\n",
      "Loaded 'comuni_EU': (122750, 12), 'EPSG:3035'\n",
      "Loaded 'comuni': (7899, 13), 'EPSG:32632'\n",
      "Loaded 'pop_grids': (4594018, 18), 'EPSG:3035'\n",
      "6 datasets loaded. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'countries' has 0.00% invalid geometries.\n",
      "Nothing to fix in 'countries'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'regions' has 5.00% invalid geometries.\n",
      "Fixed 1 geometries in 'regions'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'provinces' has 0.93% invalid geometries.\n",
      "Fixed 1 geometries in 'provinces'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'comuni_EU' has 0.00% invalid geometries.\n",
      "Nothing to fix in 'comuni_EU'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'comuni' has 0.10% invalid geometries.\n",
      "Fixed 8 geometries in 'comuni'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'pop_grids' has 0.00% invalid geometries.\n",
      "Nothing to fix in 'pop_grids'\n",
      "\n",
      "Transforming CRS...\n",
      "Changed CRS of 'countries': 'EPSG:3035' to 'EPSG:3035'\n",
      "Changed CRS of 'regions': 'EPSG:32632' to 'EPSG:3035'\n",
      "Changed CRS of 'provinces': 'EPSG:32632' to 'EPSG:3035'\n",
      "Changed CRS of 'comuni_EU': 'EPSG:3035' to 'EPSG:3035'\n",
      "Changed CRS of 'comuni': 'EPSG:32632' to 'EPSG:3035'\n",
      "Changed CRS of 'pop_grids': 'EPSG:3035' to 'EPSG:3035'\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "# file paths:\n",
    "\n",
    "path_contr = \"./data_EU/countries_shp/\"\n",
    "path_reg = \"./data_Italy/regioni/\"\n",
    "path_prov = \"./data_Italy/provinci\"\n",
    "path_com_EU = \"./data_EU/comuni_shp/\"\n",
    "path_com = \"./data_Italy/comuni/\"\n",
    "path_grids = \"./data_EU/census_grid_EU/grids_corrected.parquet\"\n",
    "\n",
    "\n",
    "# datasets:\n",
    "# format: {display_name: (path, file_format), ...}\n",
    "\n",
    "datasets = {\n",
    "    \"countries\": (path_contr, \"shapefile\"),\n",
    "    \"regions\": (path_reg, \"shapefile\"),\n",
    "    \"provinces\": (path_prov, \"shapefile\"),\n",
    "    \"comuni_EU\": (path_com_EU, \"shapefile\"),\n",
    "    \"comuni\": (path_com, \"shapefile\"),\n",
    "    \"pop_grids\": (path_grids, \"geoparquet\"),\n",
    "    # \"census\": (path_census, \"\"),\n",
    "}\n",
    "\n",
    "\n",
    "obj = Enricher(crs=\"EPSG:3035\")\n",
    "obj.setup_cluster(which=\"sedona\", ex_mem=26, dr_mem=24, log_level=\"ERROR\")\n",
    "\n",
    "obj.load(datasets, silent=True, force_repartition=True)\n",
    "obj.fix_geometries()\n",
    "obj.transform(lazy=False)\n",
    "\n",
    "# obj.dfs_list['comuni_EU'] = obj.dfs_list['comuni_EU'].filter(F.col('CNTR_ID').isin([\"IT\", \"DE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(st_geometrytype(geometry)='ST_MultiPolygon'), Row(st_geometrytype(geometry)='ST_Polygon')]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae5b32e619ab48c69c40c52c2ce95fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h1>Enrich with Overlay</h1>'), HTML(value=\"<div style='height: 5px;'></div>\"), HBo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# GUI\n",
    "\n",
    "obj_ui = EnricherUI(obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_649217/4028717082.py:11: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(x) if isinstance(x, decimal.Decimal) else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Guide: https://docs.kepler.gl/docs/keplergl-jupyter\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57c021d0e92a4ac59583292a9f4cccb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "KeplerGl(data={'df': {'index': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, …"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keplergl import KeplerGl\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "import decimal\n",
    "\n",
    "# res_agr = obj.res_agr\n",
    "\n",
    "res_agr = obj.dfs_list['provinces']\n",
    "\n",
    "df = res_agr.toPandas()\n",
    "df = df.map(lambda x: float(x) if isinstance(x, decimal.Decimal) else x)\n",
    "df['geometry'] = df['geometry'].apply(lambda geom: shape(geom))\n",
    "\n",
    "gdf = gpd.GeoDataFrame(df, geometry='geometry')\n",
    "# gdf.crs = \"EPSG:3035\"\n",
    "gdf.crs = obj.crs\n",
    "\n",
    "map = KeplerGl(height=600)\n",
    "map.add_data(data=gdf, name=\"df\")\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Guide: https://docs.kepler.gl/docs/keplergl-jupyter\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e16e3f99ae841c2bd75530148515917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "KeplerGl(data={'res_agr': {'index': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,…"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keplergl import KeplerGl\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "\n",
    "com_pop = obj.dfs_list['comuni']\n",
    "\n",
    "res_agr = com_pop.toPandas()\n",
    "res_agr['geometry'] = res_agr['geometry'].apply(lambda geom: shape(geom))\n",
    "\n",
    "gdf = gpd.GeoDataFrame(res_agr, geometry='geometry')\n",
    "gdf.crs = \"EPSG:3035\"\n",
    "\n",
    "map = KeplerGl(height=600)\n",
    "map.add_data(data=gdf, name=\"res_agr\")\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_EU_com_enriched = obj.res_agr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Guide: https://docs.kepler.gl/docs/keplergl-jupyter\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a537a4fb6604e8fab471ca6fb390dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "KeplerGl(data={'res_agr': {'index': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,…"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keplergl import KeplerGl\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "\n",
    "com_pop = obj.res_agr\n",
    "\n",
    "res_agr = com_pop.toPandas()\n",
    "res_agr['geometry'] = res_agr['geometry'].apply(lambda geom: shape(geom))\n",
    "\n",
    "gdf = gpd.GeoDataFrame(res_agr, geometry='geometry')\n",
    "gdf.crs = \"EPSG:3035\"\n",
    "\n",
    "map = KeplerGl(height=600)\n",
    "map.add_data(data=gdf, name=\"res_agr\")\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7976"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "com_pop.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11271"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.dfs_list['comuni'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sedona_venv)",
   "language": "python",
   "name": "sedona_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
