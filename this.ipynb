{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sedona.spark import *\n",
    "from contextlib import contextmanager\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import col, first, sum as _sum\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "class Enricher:\n",
    "\n",
    "    def __init__(self, crs=3035):\n",
    "        self.crs = crs\n",
    "        self.cores = None\n",
    "        self.res = None\n",
    "        self.sedona = None\n",
    "        self.res_agr = None\n",
    "        self.df1 = None\n",
    "        self.df2 = None\n",
    "            \n",
    "    def setup(self, which=\"wherobots\", ex_mem=26, dr_mem=24, log_level=None):\n",
    "        if which == \"wherobots\":\n",
    "            config = SedonaContext.builder().getOrCreate()\n",
    "            self.sedona = SedonaContext.create(config)\n",
    "            \n",
    "            self.cores = self.sedona.sparkContext.defaultParallelism\n",
    "            print(f\"Wherobots setup started with {self.cores} cores for parellelism.\")\n",
    "        elif which == \"sedona\":\n",
    "            config = SedonaContext.builder() .\\\n",
    "                config(\"spark.executor.memory\", f\"{ex_mem}g\") .\\\n",
    "                config(\"spark.driver.memory\", f\"{dr_mem}g\") .\\\n",
    "                config('spark.jars.packages',\n",
    "                    'org.apache.sedona:sedona-spark-shaded-3.5_2.12:1.7.0,'\n",
    "                    'org.datasyslab:geotools-wrapper:1.7.0-28.5'). \\\n",
    "                getOrCreate()\n",
    "\n",
    "            self.sedona = SedonaContext.create(config)\n",
    "            \n",
    "            if log_level in [\"OFF\", \"ERROR\", \"WARN\", \"INFO\", \"DEBUG\"]:\n",
    "                self.sedona.sparkContext.setLogLevel(log_level)\n",
    "                \n",
    "            self.cores = self.sedona.sparkContext.defaultParallelism\n",
    "            print(f\"Sedona initialized with {self.cores} cores for parellelism.\")\n",
    "        else:\n",
    "            raise ValueError(\"Invalid 'which'. Choose either 'wherobots' or 'sedona'\")\n",
    "        \n",
    "    \n",
    "    @contextmanager\n",
    "    def get_time(self, task_name):\n",
    "        start = time.time()\n",
    "        yield\n",
    "        elapsed = time.time() - start\n",
    "    \n",
    "        print(f\"{task_name}... DONE in {(elapsed/60):.2f} min\" \\\n",
    "              if elapsed >= 60 else f\"{task_name}... DONE in {elapsed:.2f} sec\")\n",
    "\n",
    "    def load_datsets(self, which=\"wherobots\", path1=None, path2=None):\n",
    "        print(f\"Make sure the geometry column is named \\\"geometry\\\" in the datasets\")\n",
    "        if which == \"wherobots\":\n",
    "            self.df1 = self.sedona.read.format(\"shapefile\").load(\"s3://wbts-wbc-o2l64ln0km/kc2se8vgd6/data/customer-nzdf2d7gjuu3ou/countries/\")\n",
    "            self.df2 = self.sedona.read.format(\"geoparquet\").load(\"s3://wbts-wbc-o2l64ln0km/kc2se8vgd6/data/customer-nzdf2d7gjuu3ou/bench_data/grids1.parquet\")\n",
    "\n",
    "        elif which == \"sedona\":\n",
    "            # corine_path = \"./data_Corine/land_cover_100m.parquet\"\n",
    "            # cens_path = \"./data_Italy/merged/merged_pop_geom/merged.parquet\"\n",
    "            \n",
    "            path1 = \"./data_EU/comuni_shp/\"\n",
    "            path2 = \"./data_EU/census_grid_EU/grids.parquet\"\n",
    "\n",
    "            self.df1 = self.sedona.read.format(\"shapefile\").load(path1)\n",
    "            self.df2 = self.sedona.read.format(\"geoparquet\").option(\"legacyMode\", \"true\").load(path2)\n",
    "            # cens_df = self.sedona.read.format(\"geoparquet\").option(\"legacyMode\", \"true\").load(cens_path)\n",
    "            # corine_df = self.sedona.read.format(\"geoparquet\").option(\"legacyMode\", \"true\").load(corine_path)\n",
    "            # cens_df = cens_df.withColumn(\"geometry\", expr(\"ST_MakeValid(geometry)\"))\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\"Invalid 'which'. Choose either 'wherobots' or 'sedona'\")\n",
    "        \n",
    "        print(f\"Loaded. \\n A.cols: {self.df1.columns} \\n \\n B.cols: {self.df2.columns}\\n\")\n",
    "    \n",
    "\n",
    "    def _make_cache(self, *dfs):\n",
    "        cached_dfs = []\n",
    "        for df in dfs:\n",
    "            if df.storageLevel != StorageLevel.NONE:\n",
    "                df.unpersist()\n",
    "            df.cache()\n",
    "            print(f\"Dataset cached. {df.count()} rows.\")\n",
    "            cached_dfs.append(df)\n",
    "        return cached_dfs\n",
    "    \n",
    "    def clear_memory(self, *keep):\n",
    "        if self.res.storageLevel != StorageLevel.NONE:\n",
    "            self.res.unpersist()\n",
    "        self.res = None\n",
    "    \n",
    "    def join_chey(self, group_by=None, *cols, pred=\"ST_Intersects\", rel_str=\"2********\", make_geom=True, ratio=True, aggr=True, madre=True, cache=True, grid_area=1e6):\n",
    "        join_expr = f\"{pred}(df1.geometry, df2.geometry)\"\n",
    "        if pred == \"ST_Relate\":\n",
    "            join_expr = f\"{pred}(df1.geometry, df2.geometry, '{rel_str}')\"\n",
    "\n",
    "        self.res = self.df1.alias(\"df1\").join(\n",
    "            self.df2.alias(\"df2\"), expr(join_expr)\n",
    "        ).select(\n",
    "            expr(\"df1.geometry\").alias(\"df1_geom\"),\n",
    "            expr(\"df2.geometry\").alias(\"df2_geom\"),\n",
    "            *[f\"df1.{c}\" for c in self.df1.columns if c != \"geometry\"],\n",
    "            *[f\"df2.{c}\" for c in self.df2.columns if c != \"geometry\" and c not in self.df1.columns]\n",
    "        )\n",
    "\n",
    "        if make_geom:\n",
    "            self.res = self.res.withColumn(\"intr_geom\", expr(\"ST_Intersection(df1_geom, df2_geom)\"))\n",
    "            if ratio:\n",
    "                if grid_area > 0:\n",
    "                    self.res = self.res.withColumn(\"intr_ratio\", expr(f\"ST_Area(intr_geom) / {grid_area}\"))\n",
    "                else:\n",
    "                    self.res = self.res.withColumn(\"intr_ratio\", expr(\"ST_Area(intr_geom) / ST_Area(df2_geom)\"))\n",
    "        \n",
    "        if aggr:\n",
    "            if not ratio:\n",
    "                self.res_agr = self.res.groupBy(group_by).\\\n",
    "                    agg(*([first(col(c)).alias(c) for c in self.res.columns if c not in cols and c != group_by]\\\n",
    "                        + [_sum(col(c)).alias(f\"agr_{c}\") for c in cols]))\n",
    "            else:\n",
    "                if \"intr_ratio\" not in self.res.columns:\n",
    "                    raise ValueError(\"ratio column not found. run 'make_int_ratio()' first\")\n",
    "                self.res_agr = self.res.groupBy(group_by).\\\n",
    "                    agg(*([first(col(c)).alias(c) for c in self.res.columns if c not in cols and c != group_by]\\\n",
    "                    + [ceil(_sum(col(c) * col(\"intr_ratio\"))).alias(f\"agr_{c}\") for c in cols])\n",
    "                )\n",
    "            if madre:\n",
    "                self.res = self.res.join(self.res_agr, on=group_by, how=\"left\")\n",
    "            \n",
    "            if cache:\n",
    "                if madre:\n",
    "                    self._make_cache(self.res)\n",
    "                self._make_cache(self.res_agr)\n",
    "            return self.res_agr\n",
    "        \n",
    "        else:\n",
    "            return self.res\n",
    "\n",
    "    def export(self, df=\"madre\", path=\"outputs\", name=\"unnamed\", how=\"repartition\", num=None, clear=False):\n",
    "        if num is None:\n",
    "            num = self.cores\n",
    "        if how == \"repartition\":\n",
    "            self.res = self.res.repartition(num)\n",
    "        elif how == \"coalesce\":\n",
    "            self.res = self.res.coalesce(num)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid 'how'. Choose either 'repartition' or 'coalesce'\")\n",
    "\n",
    "        if df == \"madre\":\n",
    "            self.res.write.mode(\"overwrite\").format(\"geoparquet\").save(f\"./{path}/\" + f\"/{name}\")\n",
    "        else:\n",
    "            self.res_agr.write.mode(\"overwrite\").format(\"geoparquet\").save(f\"./{path}/\" + f\"/{name}_agr\")\n",
    "        \n",
    "        if clear:\n",
    "            self.clear_memory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sedona.spark import *\n",
    "from contextlib import contextmanager\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import col, first, sum as _sum\n",
    "import time\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import sys\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "class Enricher:\n",
    "\n",
    "    def __init__(self, crs=3035):\n",
    "        self.crs = crs\n",
    "        self.cores = None\n",
    "        self.res = None\n",
    "        self.sedona = None\n",
    "        self.res_agr = None\n",
    "        self.df1 = None\n",
    "        self.df2 = None\n",
    "            \n",
    "    def setup(self, which=\"wherobots\", ex_mem=26, dr_mem=24, log_level=None):\n",
    "        if which == \"wherobots\":\n",
    "            config = SedonaContext.builder().getOrCreate()\n",
    "            self.sedona = SedonaContext.create(config)\n",
    "            \n",
    "            self.cores = self.sedona.sparkContext.defaultParallelism\n",
    "            print(f\"Wherobots setup started with {self.cores} cores for parellelism.\")\n",
    "        elif which == \"sedona\":\n",
    "            config = SedonaContext.builder() .\\\n",
    "                config(\"spark.executor.memory\", f\"{ex_mem}g\") .\\\n",
    "                config(\"spark.driver.memory\", f\"{dr_mem}g\") .\\\n",
    "                config('spark.jars.packages',\n",
    "                    'org.apache.sedona:sedona-spark-shaded-3.5_2.12:1.7.0,'\n",
    "                    'org.datasyslab:geotools-wrapper:1.7.0-28.5'). \\\n",
    "                getOrCreate()\n",
    "\n",
    "            self.sedona = SedonaContext.create(config)\n",
    "            \n",
    "            if log_level in [\"OFF\", \"ERROR\", \"WARN\", \"INFO\", \"DEBUG\"]:\n",
    "                self.sedona.sparkContext.setLogLevel(log_level)\n",
    "                \n",
    "            self.cores = self.sedona.sparkContext.defaultParallelism\n",
    "            print(f\"Sedona initialized with {self.cores} cores for parellelism.\")\n",
    "        else:\n",
    "            raise ValueError(\"Invalid 'which'. Choose either 'wherobots' or 'sedona'\")\n",
    "        \n",
    "    \n",
    "    @contextmanager\n",
    "    def get_time(self, task_name):\n",
    "        start = time.time()\n",
    "        yield\n",
    "        elapsed = time.time() - start\n",
    "    \n",
    "        print(f\"{task_name}... DONE in {(elapsed/60):.2f} min\" \\\n",
    "              if elapsed >= 60 else f\"{task_name}... DONE in {elapsed:.2f} sec\")\n",
    "\n",
    "    def load_datsets(self, which=\"wherobots\", path1=None, path2=None):\n",
    "        print(f\"Make sure the geometry column is named \\\"geometry\\\" in the datasets\")\n",
    "        if which == \"wherobots\":\n",
    "            self.df1 = self.sedona.read.format(\"shapefile\").load(\"s3://wbts-wbc-o2l64ln0km/kc2se8vgd6/data/customer-nzdf2d7gjuu3ou/countries/\")\n",
    "            self.df2 = self.sedona.read.format(\"geoparquet\").load(\"s3://wbts-wbc-o2l64ln0km/kc2se8vgd6/data/customer-nzdf2d7gjuu3ou/bench_data/grids1.parquet\")\n",
    "\n",
    "        elif which == \"sedona\":\n",
    "            # corine_path = \"./data_Corine/land_cover_100m.parquet\"\n",
    "            # cens_path = \"./data_Italy/merged/merged_pop_geom/merged.parquet\"\n",
    "            \n",
    "            path1 = \"./data_EU/comuni_shp/\"\n",
    "            path2 = \"./data_EU/census_grid_EU/grids.parquet\"\n",
    "\n",
    "            self.df1 = self.sedona.read.format(\"shapefile\").load(path1)\n",
    "            self.df2 = self.sedona.read.format(\"geoparquet\").option(\"legacyMode\", \"true\").load(path2)\n",
    "            # cens_df = self.sedona.read.format(\"geoparquet\").option(\"legacyMode\", \"true\").load(cens_path)\n",
    "            # corine_df = self.sedona.read.format(\"geoparquet\").option(\"legacyMode\", \"true\").load(corine_path)\n",
    "            # cens_df = cens_df.withColumn(\"geometry\", expr(\"ST_MakeValid(geometry)\"))\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\"Invalid 'which'. Choose either 'wherobots' or 'sedona'\")\n",
    "        \n",
    "        print(f\"Loaded. \\n A.cols: {self.df1.columns} \\n \\n B.cols: {self.df2.columns}\\n\")\n",
    "    \n",
    "\n",
    "    def _make_cache(self, *dfs):\n",
    "        cached_dfs = []\n",
    "        for df in dfs:\n",
    "            if df.storageLevel != StorageLevel.NONE:\n",
    "                df.unpersist()\n",
    "            df.cache()\n",
    "            print(f\"Dataset cached. {df.count()} rows.\")\n",
    "            cached_dfs.append(df)\n",
    "        return cached_dfs\n",
    "    \n",
    "    def clear_memory(self, *keep):\n",
    "        if self.res.storageLevel != StorageLevel.NONE:\n",
    "            self.res.unpersist()\n",
    "        self.res = None\n",
    "    \n",
    "    def join_chey(self, *cols, group_by=None, pred=\"ST_Intersects\", rel_str=\"2********\", make_geom=True, ratio=True, aggr=True, madre=True, cache=True, grid_area=1e6):\n",
    "        join_expr = f\"{pred}(df1.geometry, df2.geometry)\"\n",
    "        if pred == \"ST_Relate\":\n",
    "            join_expr = f\"{pred}(df1.geometry, df2.geometry, '{rel_str}')\"\n",
    "\n",
    "        self.res = self.df1.alias(\"df1\").join(\n",
    "            self.df2.alias(\"df2\"), expr(join_expr)\n",
    "        ).select(\n",
    "            expr(\"df1.geometry\").alias(\"df1_geom\"),\n",
    "            expr(\"df2.geometry\").alias(\"df2_geom\"),\n",
    "            *[f\"df1.{c}\" for c in self.df1.columns if c != \"geometry\"],\n",
    "            *[f\"df2.{c}\" for c in self.df2.columns if c != \"geometry\" and c not in self.df1.columns]\n",
    "        )\n",
    "\n",
    "        if make_geom:\n",
    "            self.res = self.res.withColumn(\"intr_geom\", expr(\"ST_Intersection(df1_geom, df2_geom)\"))\n",
    "            if ratio:\n",
    "                if grid_area > 0:\n",
    "                    self.res = self.res.withColumn(\"intr_ratio\", expr(f\"ST_Area(intr_geom) / {grid_area}\"))\n",
    "                else:\n",
    "                    self.res = self.res.withColumn(\"intr_ratio\", expr(\"ST_Area(intr_geom) / ST_Area(df2_geom)\"))\n",
    "        \n",
    "        if aggr:\n",
    "            if not ratio:\n",
    "                self.res_agr = self.res.groupBy(group_by).\\\n",
    "                    agg(*([first(col(c)).alias(c) for c in self.res.columns if c not in cols and c != group_by]\\\n",
    "                        + [_sum(col(c)).alias(f\"agr_{c}\") for c in cols]))\n",
    "            else:\n",
    "                if \"intr_ratio\" not in self.res.columns:\n",
    "                    raise ValueError(\"ratio column not found. run 'make_int_ratio()' first\")\n",
    "                self.res_agr = self.res.groupBy(group_by).\\\n",
    "                    agg(*([first(col(c)).alias(c) for c in self.res.columns if c not in cols and c != group_by]\\\n",
    "                    + [ceil(_sum(col(c) * col(\"intr_ratio\"))).alias(f\"agr_{c}\") for c in cols])\n",
    "                )\n",
    "            if madre:\n",
    "                self.res = self.res.join(self.res_agr, on=group_by, how=\"left\")\n",
    "            \n",
    "        if cache:\n",
    "            if aggr:\n",
    "                self._make_cache(self.res_agr)\n",
    "            self._make_cache(self.res)\n",
    "\n",
    "        return self.res\n",
    "\n",
    "    def export(self, df=\"madre\", path=\"outputs\", name=\"unnamed\", how=\"repartition\", num=None, clear=False):\n",
    "        if num is None:\n",
    "            num = self.cores\n",
    "        if how == \"repartition\":\n",
    "            self.res = self.res.repartition(num)\n",
    "        elif how == \"coalesce\":\n",
    "            self.res = self.res.coalesce(num)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid 'how'. Choose either 'repartition' or 'coalesce'\")\n",
    "\n",
    "        if df == \"madre\":\n",
    "            self.res.write.mode(\"overwrite\").format(\"geoparquet\").save(f\"./{path}/\" + f\"/{name}\")\n",
    "        else:\n",
    "            self.res_agr.write.mode(\"overwrite\").format(\"geoparquet\").save(f\"./{path}/\" + f\"/{name}_agr\")\n",
    "        \n",
    "        if clear:\n",
    "            self.clear_memory()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from io import StringIO\n",
    "import sys\n",
    "\n",
    "class EnricherUI:\n",
    "    def __init__(self, enricher):\n",
    "        self.enricher = enricher\n",
    "        self.selected_cols = []  # Track selected columns for aggregation\n",
    "        self.group_by_col = None  # Track the selected group_by column\n",
    "        self._init_ui()\n",
    "\n",
    "    def _init_ui(self):\n",
    "        # Heading: Join\n",
    "        self.join_heading = widgets.HTML(value=\"<h2>Join</h2>\")\n",
    "\n",
    "        # Checkboxes for Join\n",
    "        self.make_geom_checkbox = widgets.Checkbox(value=False, description=\"Make Geometry\")\n",
    "        self.intr_ratio_checkbox = widgets.Checkbox(value=False, description=\"Intersection Ratio\")\n",
    "        self.madre_checkbox = widgets.Checkbox(value=False, description=\"Madre\")\n",
    "\n",
    "        # Text boxes for Predicate and Rel Str\n",
    "        self.predicate_text = widgets.Text(value=\"ST_Intersects\", description=\"Predicate:\")\n",
    "        self.rel_str_text = widgets.Text(value=\"2********\", description=\"Rel Str:\")\n",
    "\n",
    "        # Grid area text box (disabled by default)\n",
    "        self.grid_area_text = widgets.FloatText(value=1e6, description=\"Grid Area:\", disabled=True)\n",
    "\n",
    "        # Checkboxes for Cache and Aggregate\n",
    "        self.cache_checkbox = widgets.Checkbox(value=True, description=\"Cache\")\n",
    "        self.aggregate_checkbox = widgets.Checkbox(value=False, description=\"Aggregate\")\n",
    "\n",
    "        # Group by dropdown (disabled by default)\n",
    "        self.group_by_dropdown = widgets.Dropdown(options=self.enricher.df1.columns, description=\"Group By:\", disabled=True)\n",
    "\n",
    "        # Aggregate columns dropdown (disabled by default)\n",
    "        self.agg_cols_dropdown = widgets.SelectMultiple(options=self.enricher.df2.columns, description=\"Aggregate Cols:\", disabled=True)\n",
    "\n",
    "        # Selected aggregate columns display\n",
    "        self.selected_agg_cols_label = widgets.Label(value=\"Selected cols to aggregate:\")\n",
    "        self.selected_agg_cols = widgets.Select(options=[], description=\"Selected:\")\n",
    "\n",
    "        # Selected group_by column display\n",
    "        self.selected_group_by_label = widgets.Label(value=\"Selected group_by column:\")\n",
    "        self.selected_group_by = widgets.Label(value=\"None\")\n",
    "\n",
    "        # Join button\n",
    "        self.join_button = widgets.Button(description=\"Join\")\n",
    "\n",
    "        # Heading: Export\n",
    "        self.export_heading = widgets.HTML(value=\"<h2>Export</h2>\")\n",
    "\n",
    "        # Export fields\n",
    "        self.df_text = widgets.Text(value=\"madre\", description=\"DF:\")\n",
    "        self.path_text = widgets.Text(value=\"outputs\", description=\"Path:\")\n",
    "        self.name_text = widgets.Text(value=\"unnamed\", description=\"Name:\")\n",
    "        self.how_text = widgets.Text(value=\"repartition\", description=\"How:\")\n",
    "        self.num_text = widgets.IntText(value=self.enricher.cores, description=\"Num:\")\n",
    "        self.clear_checkbox = widgets.Checkbox(value=False, description=\"Clear\")\n",
    "        self.export_button = widgets.Button(description=\"Export\")\n",
    "\n",
    "        # Console output text box\n",
    "        self.console_output = widgets.Textarea(value=\"\", description=\"Console:\", layout=widgets.Layout(width=\"100%\", height=\"200px\"))\n",
    "        self.clear_console_button = widgets.Button(description=\"Clear Console\")\n",
    "\n",
    "        # Layout\n",
    "        self._setup_layout()\n",
    "        self._setup_event_handlers()\n",
    "\n",
    "    def _setup_layout(self):\n",
    "        # Join section\n",
    "        self.join_section = widgets.VBox([\n",
    "            self.join_heading,\n",
    "            widgets.HBox([self.make_geom_checkbox, self.intr_ratio_checkbox, self.madre_checkbox]),\n",
    "            widgets.HBox([self.predicate_text, self.rel_str_text]),\n",
    "            self.grid_area_text,\n",
    "            widgets.HBox([self.cache_checkbox, self.aggregate_checkbox]),\n",
    "            self.group_by_dropdown,\n",
    "            self.selected_group_by_label,\n",
    "            self.selected_group_by,\n",
    "            self.agg_cols_dropdown,\n",
    "            self.selected_agg_cols_label,\n",
    "            self.selected_agg_cols,\n",
    "            self.join_button\n",
    "        ])\n",
    "\n",
    "        # Export section\n",
    "        self.export_section = widgets.VBox([\n",
    "            self.export_heading,\n",
    "            self.df_text,\n",
    "            self.path_text,\n",
    "            self.name_text,\n",
    "            self.how_text,\n",
    "            self.num_text,\n",
    "            self.clear_checkbox,\n",
    "            self.export_button\n",
    "        ])\n",
    "\n",
    "        # Console section\n",
    "        self.console_section = widgets.VBox([\n",
    "            self.console_output,\n",
    "            self.clear_console_button\n",
    "        ])\n",
    "\n",
    "        # Display everything\n",
    "        display(widgets.VBox([self.join_section, self.export_section, self.console_section]))\n",
    "\n",
    "    def _setup_event_handlers(self):\n",
    "        # Enable/disable grid area based on intr_ratio checkbox\n",
    "        def on_intr_ratio_change(change):\n",
    "            self.grid_area_text.disabled = not change['new']\n",
    "        self.intr_ratio_checkbox.observe(on_intr_ratio_change, names='value')\n",
    "\n",
    "        # Enable/disable group by and aggregate cols based on aggregate checkbox\n",
    "        def on_aggregate_change(change):\n",
    "            self.group_by_dropdown.disabled = not change['new']\n",
    "            self.agg_cols_dropdown.disabled = not change['new']\n",
    "        self.aggregate_checkbox.observe(on_aggregate_change, names='value')\n",
    "\n",
    "        # Handle selection of group_by column\n",
    "        def on_group_by_change(change):\n",
    "            self.group_by_col = change['new']\n",
    "            self.selected_group_by.value = self.group_by_col\n",
    "        self.group_by_dropdown.observe(on_group_by_change, names='value')\n",
    "\n",
    "        # Handle selection of aggregate columns\n",
    "        def on_agg_cols_change(change):\n",
    "            self.update_selected_columns(change)\n",
    "        self.agg_cols_dropdown.observe(on_agg_cols_change, names='value')\n",
    "\n",
    "        # Join button click handler\n",
    "        def on_join_button_click(b):\n",
    "            # Capture console output\n",
    "            old_stdout = sys.stdout\n",
    "            sys.stdout = captured_output = StringIO()\n",
    "\n",
    "            try:\n",
    "                group_by = self.group_by_col if self.aggregate_checkbox.value else None\n",
    "                agg_cols = self.selected_cols if self.aggregate_checkbox.value else []\n",
    "\n",
    "                self.enricher.join_chey(\n",
    "                    group_by=group_by,\n",
    "                    pred=self.predicate_text.value,\n",
    "                    rel_str=self.rel_str_text.value,\n",
    "                    make_geom=self.make_geom_checkbox.value,\n",
    "                    ratio=self.intr_ratio_checkbox.value,\n",
    "                    aggr=self.aggregate_checkbox.value,\n",
    "                    madre=self.madre_checkbox.value,\n",
    "                    cache=self.cache_checkbox.value,\n",
    "                    grid_area=self.grid_area_text.value,\n",
    "                    *agg_cols\n",
    "                )\n",
    "                # print(f\"pred: {self.predicate_text.value}, \\n rel_str: {self.rel_str_text.value} \\n make_geom: {self.make_geom_checkbox.value} \\n ratio: {self.intr_ratio_checkbox.value} \\n aggr: {self.aggregate_checkbox.value} \\n madre: {self.madre_checkbox.value} \\n cache: {self.cache_checkbox.value} \\n grid_area: {self.grid_area_text.value}\")\n",
    "                print(\"Join operation completed.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {str(e)}\")\n",
    "            finally:\n",
    "                sys.stdout = old_stdout\n",
    "                self.console_output.value += captured_output.getvalue()\n",
    "\n",
    "        self.join_button.on_click(on_join_button_click)\n",
    "\n",
    "        # Export button click handler\n",
    "        def on_export_button_click(b):\n",
    "            # Capture console output\n",
    "            old_stdout = sys.stdout\n",
    "            sys.stdout = captured_output = StringIO()\n",
    "\n",
    "            try:\n",
    "                self.enricher.export(\n",
    "                    df=self.df_text.value,\n",
    "                    path=self.path_text.value,\n",
    "                    name=self.name_text.value,\n",
    "                    how=self.how_text.value,\n",
    "                    num=self.num_text.value,\n",
    "                    clear=self.clear_checkbox.value\n",
    "                )\n",
    "                print(\"Export operation completed.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {str(e)}\")\n",
    "            finally:\n",
    "                sys.stdout = old_stdout\n",
    "                self.console_output.value += captured_output.getvalue()\n",
    "\n",
    "        self.export_button.on_click(on_export_button_click)\n",
    "\n",
    "        # Clear console button click handler\n",
    "        def on_clear_console_button_click(b):\n",
    "            self.console_output.value = \"\"\n",
    "        self.clear_console_button.on_click(on_clear_console_button_click)\n",
    "\n",
    "    def update_selected_columns(self, change):\n",
    "        \"\"\"Update the list of selected columns for group_by and aggregate_cols.\"\"\"\n",
    "        # Add newly selected columns to the selected list\n",
    "        for col in change[\"new\"]:\n",
    "            if col not in self.selected_cols:\n",
    "                self.selected_cols.append(col)\n",
    "    \n",
    "        # Update the dropdown options to disable already selected columns\n",
    "        available_options = [col for col in self.enricher.df2.columns if col not in self.selected_cols]\n",
    "        self.agg_cols_dropdown.options = available_options\n",
    "    \n",
    "        # Update the display of selected columns\n",
    "        self.selected_agg_cols.options = self.selected_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sedona.spark import *\n",
    "from contextlib import contextmanager\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import col, first, sum as _sum\n",
    "import time\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import sys\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "class Enricher:\n",
    "\n",
    "    def __init__(self, crs=3035):\n",
    "        self.crs = crs\n",
    "        self.cores = None\n",
    "        self.res = None\n",
    "        self.sedona = None\n",
    "        self.res_agr = None\n",
    "        self.df1 = None\n",
    "        self.df2 = None\n",
    "            \n",
    "    def setup(self, which=\"wherobots\", ex_mem=26, dr_mem=24, log_level=None):\n",
    "        if which == \"wherobots\":\n",
    "            config = SedonaContext.builder().getOrCreate()\n",
    "            self.sedona = SedonaContext.create(config)\n",
    "            \n",
    "            self.cores = self.sedona.sparkContext.defaultParallelism\n",
    "            print(f\"Wherobots setup started with {self.cores} cores for parellelism.\")\n",
    "        elif which == \"sedona\":\n",
    "            config = SedonaContext.builder() .\\\n",
    "                config(\"spark.executor.memory\", f\"{ex_mem}g\") .\\\n",
    "                config(\"spark.driver.memory\", f\"{dr_mem}g\") .\\\n",
    "                config('spark.jars.packages',\n",
    "                    'org.apache.sedona:sedona-spark-shaded-3.5_2.12:1.7.0,'\n",
    "                    'org.datasyslab:geotools-wrapper:1.7.0-28.5'). \\\n",
    "                getOrCreate()\n",
    "\n",
    "            self.sedona = SedonaContext.create(config)\n",
    "            \n",
    "            if log_level in [\"OFF\", \"ERROR\", \"WARN\", \"INFO\", \"DEBUG\"]:\n",
    "                self.sedona.sparkContext.setLogLevel(log_level)\n",
    "                \n",
    "            self.cores = self.sedona.sparkContext.defaultParallelism\n",
    "            print(f\"Sedona initialized with {self.cores} cores for parellelism.\")\n",
    "        else:\n",
    "            raise ValueError(\"Invalid 'which'. Choose either 'wherobots' or 'sedona'\")\n",
    "        \n",
    "    \n",
    "    @contextmanager\n",
    "    def get_time(self, task_name):\n",
    "        start = time.time()\n",
    "        yield\n",
    "        elapsed = time.time() - start\n",
    "    \n",
    "        print(f\"{task_name}... DONE in {(elapsed/60):.2f} min\" \\\n",
    "              if elapsed >= 60 else f\"{task_name}... DONE in {elapsed:.2f} sec\")\n",
    "\n",
    "    def load_datsets(self, which=\"wherobots\", path1=None, path2=None):\n",
    "        print(f\"Make sure the geometry column is named \\\"geometry\\\" in the datasets\")\n",
    "        if which == \"wherobots\":\n",
    "            self.df1 = self.sedona.read.format(\"shapefile\").load(\"s3://wbts-wbc-o2l64ln0km/kc2se8vgd6/data/customer-nzdf2d7gjuu3ou/countries/\")\n",
    "            self.df2 = self.sedona.read.format(\"geoparquet\").load(\"s3://wbts-wbc-o2l64ln0km/kc2se8vgd6/data/customer-nzdf2d7gjuu3ou/bench_data/grids1.parquet\")\n",
    "\n",
    "        elif which == \"sedona\":\n",
    "            # corine_path = \"./data_Corine/land_cover_100m.parquet\"\n",
    "            # cens_path = \"./data_Italy/merged/merged_pop_geom/merged.parquet\"\n",
    "            \n",
    "            path1 = \"./data_EU/comuni_shp/\"\n",
    "            path2 = \"./data_EU/census_grid_EU/grids.parquet\"\n",
    "\n",
    "            self.df1 = self.sedona.read.format(\"shapefile\").load(path1)\n",
    "            self.df2 = self.sedona.read.format(\"geoparquet\").option(\"legacyMode\", \"true\").load(path2)\n",
    "            # cens_df = self.sedona.read.format(\"geoparquet\").option(\"legacyMode\", \"true\").load(cens_path)\n",
    "            # corine_df = self.sedona.read.format(\"geoparquet\").option(\"legacyMode\", \"true\").load(corine_path)\n",
    "            # cens_df = cens_df.withColumn(\"geometry\", expr(\"ST_MakeValid(geometry)\"))\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\"Invalid 'which'. Choose either 'wherobots' or 'sedona'\")\n",
    "        \n",
    "        print(f\"Loaded. \\n A.cols: {self.df1.columns} \\n \\n B.cols: {self.df2.columns}\\n\")\n",
    "    \n",
    "\n",
    "    def _make_cache(self, *dfs):\n",
    "        cached_dfs = []\n",
    "        for df in dfs:\n",
    "            if df.storageLevel != StorageLevel.NONE:\n",
    "                df.unpersist()\n",
    "            df.cache()\n",
    "            print(f\"Dataset cached. {df.count()} rows.\")\n",
    "            cached_dfs.append(df)\n",
    "        return cached_dfs\n",
    "    \n",
    "    def clear_memory(self, *keep):\n",
    "        if self.res.storageLevel != StorageLevel.NONE:\n",
    "            self.res.unpersist()\n",
    "        self.res = None\n",
    "    \n",
    "    def join_chey(self, *cols, group_by=None, pred=\"ST_Intersects\", rel_str=\"2********\", make_geom=True, ratio=True, aggr=True, madre=True, cache=True, grid_area=1e6):\n",
    "        join_expr = f\"{pred}(df1.geometry, df2.geometry)\"\n",
    "        if pred == \"ST_Relate\":\n",
    "            join_expr = f\"{pred}(df1.geometry, df2.geometry, '{rel_str}')\"\n",
    "\n",
    "        self.res = self.df1.alias(\"df1\").join(\n",
    "            self.df2.alias(\"df2\"), expr(join_expr)\n",
    "        ).select(\n",
    "            expr(\"df1.geometry\").alias(\"df1_geom\"),\n",
    "            expr(\"df2.geometry\").alias(\"df2_geom\"),\n",
    "            *[f\"df1.{c}\" for c in self.df1.columns if c != \"geometry\"],\n",
    "            *[f\"df2.{c}\" for c in self.df2.columns if c != \"geometry\" and c not in self.df1.columns]\n",
    "        )\n",
    "\n",
    "        if make_geom:\n",
    "            self.res = self.res.withColumn(\"intr_geom\", expr(\"ST_Intersection(df1_geom, df2_geom)\"))\n",
    "            if ratio:\n",
    "                if grid_area > 0:\n",
    "                    self.res = self.res.withColumn(\"intr_ratio\", expr(f\"ST_Area(intr_geom) / {grid_area}\"))\n",
    "                else:\n",
    "                    self.res = self.res.withColumn(\"intr_ratio\", expr(\"ST_Area(intr_geom) / ST_Area(df2_geom)\"))\n",
    "        \n",
    "        if aggr:\n",
    "            if not ratio:\n",
    "                self.res_agr = self.res.groupBy(group_by).\\\n",
    "                    agg(*([first(col(c)).alias(c) for c in self.res.columns if c not in cols and c != group_by]\\\n",
    "                        + [_sum(col(c)).alias(f\"agr_{c}\") for c in cols]))\n",
    "            else:\n",
    "                if \"intr_ratio\" not in self.res.columns:\n",
    "                    raise ValueError(\"ratio column not found. run 'make_int_ratio()' first\")\n",
    "                self.res_agr = self.res.groupBy(group_by).\\\n",
    "                    agg(*([first(col(c)).alias(c) for c in self.res.columns if c not in cols and c != group_by]\\\n",
    "                    + [ceil(_sum(col(c) * col(\"intr_ratio\"))).alias(f\"agr_{c}\") for c in cols])\n",
    "                )\n",
    "            if madre:\n",
    "                self.res = self.res.join(self.res_agr, on=group_by, how=\"left\")\n",
    "            \n",
    "        if cache:\n",
    "            if aggr:\n",
    "                self._make_cache(self.res_agr)\n",
    "            self._make_cache(self.res)\n",
    "\n",
    "        return self.res\n",
    "\n",
    "    def export(self, df=\"madre\", path=\"outputs\", name=\"unnamed\", how=\"repartition\", num=None, clear=False):\n",
    "        if num is None:\n",
    "            num = self.cores\n",
    "        if how == \"repartition\":\n",
    "            self.res = self.res.repartition(num)\n",
    "        elif how == \"coalesce\":\n",
    "            self.res = self.res.coalesce(num)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid 'how'. Choose either 'repartition' or 'coalesce'\")\n",
    "\n",
    "        if df == \"madre\":\n",
    "            self.res.write.mode(\"overwrite\").format(\"geoparquet\").save(f\"./{path}/\" + f\"/{name}\")\n",
    "        else:\n",
    "            self.res_agr.write.mode(\"overwrite\").format(\"geoparquet\").save(f\"./{path}/\" + f\"/{name}_agr\")\n",
    "        \n",
    "        if clear:\n",
    "            self.clear_memory()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from io import StringIO\n",
    "import sys\n",
    "import logging\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "class EnricherUI:\n",
    "    def __init__(self, enricher):\n",
    "        self.enricher = enricher\n",
    "        self.selected_cols = []\n",
    "        self.group_by_col = None\n",
    "        self._init_ui()\n",
    "\n",
    "    def capture_output(self, func, *args, **kwargs):\n",
    "        \"\"\"Capture standard output and Spark logs, redirecting them to the console box.\"\"\"\n",
    "        # Create a StringIO buffer to capture output\n",
    "        buffer = StringIO()\n",
    "\n",
    "        # Redirect sys.stdout to the buffer\n",
    "        old_stdout = sys.stdout\n",
    "        sys.stdout = buffer\n",
    "\n",
    "        # Redirect Spark logs to the buffer\n",
    "        spark_logger = logging.getLogger(\"py4j\")\n",
    "        spark_logger.setLevel(logging.INFO)\n",
    "        handler = logging.StreamHandler(buffer)\n",
    "        spark_logger.addHandler(handler)\n",
    "\n",
    "        try:\n",
    "            func(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            buffer.write(f\"Error: {str(e)}\\n\")\n",
    "        finally:\n",
    "            sys.stdout = old_stdout\n",
    "            spark_logger.removeHandler(handler)\n",
    "\n",
    "            # Update the console box with the captured output\n",
    "            self.console_output.value += buffer.getvalue()\n",
    "\n",
    "\n",
    "    def _init_ui(self):\n",
    "        # Heading: Join\n",
    "        self.join_heading = widgets.HTML(value=\"<h2>Join</h2>\")\n",
    "\n",
    "        # Checkboxes for Join\n",
    "        self.make_geom_checkbox = widgets.Checkbox(value=False, description=\"Make Geometry\")\n",
    "        self.intr_ratio_checkbox = widgets.Checkbox(value=False, description=\"Intersection Ratio\")\n",
    "        self.madre_checkbox = widgets.Checkbox(value=False, description=\"Madre\")\n",
    "\n",
    "        # Text boxes for Predicate and Rel Str\n",
    "        self.predicate_text = widgets.Text(value=\"ST_Intersects\", description=\"Predicate:\")\n",
    "        self.rel_str_text = widgets.Text(value=\"2********\", description=\"Rel Str:\")\n",
    "\n",
    "        # Grid area text box (disabled by default)\n",
    "        self.grid_area_text = widgets.FloatText(value=1e6, description=\"Grid Area:\", disabled=True)\n",
    "\n",
    "        # Checkboxes for Cache and Aggregate\n",
    "        self.cache_checkbox = widgets.Checkbox(value=True, description=\"Cache\")\n",
    "        self.aggregate_checkbox = widgets.Checkbox(value=False, description=\"Aggregate\")\n",
    "\n",
    "        # Group by dropdown (disabled by default)\n",
    "        self.group_by_dropdown = widgets.Dropdown(options=self.enricher.df1.columns, description=\"Group By:\", disabled=True)\n",
    "\n",
    "        # Aggregate columns dropdown (disabled by default)\n",
    "        self.agg_cols_dropdown = widgets.SelectMultiple(options=self.enricher.df2.columns, description=\"Aggregate Cols:\", disabled=True)\n",
    "\n",
    "        # Selected aggregate columns display\n",
    "        self.selected_agg_cols_label = widgets.Label(value=\"Selected cols to aggregate:\")\n",
    "        self.selected_agg_cols = widgets.Select(options=[], description=\"Selected:\")\n",
    "\n",
    "        # Selected group_by column display\n",
    "        self.selected_group_by_label = widgets.Label(value=\"Selected group_by column:\")\n",
    "        self.selected_group_by = widgets.Label(value=\"None\")\n",
    "\n",
    "        # Join button\n",
    "        self.join_button = widgets.Button(description=\"Join\")\n",
    "\n",
    "        # Heading: Export\n",
    "        self.export_heading = widgets.HTML(value=\"<h2>Export</h2>\")\n",
    "\n",
    "        # Export fields\n",
    "        self.df_text = widgets.Text(value=\"madre\", description=\"DF:\")\n",
    "        self.path_text = widgets.Text(value=\"outputs\", description=\"Path:\")\n",
    "        self.name_text = widgets.Text(value=\"unnamed\", description=\"Name:\")\n",
    "        self.how_text = widgets.Text(value=\"repartition\", description=\"How:\")\n",
    "        self.num_text = widgets.IntText(value=self.enricher.cores, description=\"Num:\")\n",
    "        self.clear_checkbox = widgets.Checkbox(value=False, description=\"Clear\")\n",
    "        self.export_button = widgets.Button(description=\"Export\")\n",
    "\n",
    "        # Console output text box\n",
    "        self.console_output = widgets.Textarea(value=\"\", description=\"Console:\", layout=widgets.Layout(width=\"100%\", height=\"200px\"))\n",
    "        self.clear_console_button = widgets.Button(description=\"Clear Console\")\n",
    "\n",
    "        # Layout\n",
    "        self._setup_layout()\n",
    "        self._setup_event_handlers()\n",
    "\n",
    "    def _setup_layout(self):\n",
    "        # Join section\n",
    "        self.join_section = widgets.VBox([\n",
    "            self.join_heading,\n",
    "            widgets.HBox([self.make_geom_checkbox, self.intr_ratio_checkbox, self.madre_checkbox]),\n",
    "            widgets.HBox([self.predicate_text, self.rel_str_text]),\n",
    "            self.grid_area_text,\n",
    "            widgets.HBox([self.cache_checkbox, self.aggregate_checkbox]),\n",
    "            self.group_by_dropdown,\n",
    "            self.selected_group_by_label,\n",
    "            self.selected_group_by,\n",
    "            self.agg_cols_dropdown,\n",
    "            self.selected_agg_cols_label,\n",
    "            self.selected_agg_cols,\n",
    "            self.join_button\n",
    "        ])\n",
    "\n",
    "        # Export section\n",
    "        self.export_section = widgets.VBox([\n",
    "            self.export_heading,\n",
    "            self.df_text,\n",
    "            self.path_text,\n",
    "            self.name_text,\n",
    "            self.how_text,\n",
    "            self.num_text,\n",
    "            self.clear_checkbox,\n",
    "            self.export_button\n",
    "        ])\n",
    "\n",
    "        # Console section\n",
    "        self.console_section = widgets.VBox([\n",
    "            self.console_output,\n",
    "            self.clear_console_button\n",
    "        ])\n",
    "\n",
    "        # Display everything\n",
    "        display(widgets.VBox([self.join_section, self.export_section, self.console_section]))\n",
    "\n",
    "    def _setup_event_handlers(self):\n",
    "        # Enable/disable grid area based on intr_ratio checkbox\n",
    "        def on_intr_ratio_change(change):\n",
    "            self.grid_area_text.disabled = not change['new']\n",
    "        self.intr_ratio_checkbox.observe(on_intr_ratio_change, names='value')\n",
    "\n",
    "        # Enable/disable group by and aggregate cols based on aggregate checkbox\n",
    "        def on_aggregate_change(change):\n",
    "            self.group_by_dropdown.disabled = not change['new']\n",
    "            self.agg_cols_dropdown.disabled = not change['new']\n",
    "        self.aggregate_checkbox.observe(on_aggregate_change, names='value')\n",
    "\n",
    "        # Handle selection of group_by column\n",
    "        def on_group_by_change(change):\n",
    "            self.group_by_col = change['new']\n",
    "            self.selected_group_by.value = self.group_by_col\n",
    "        self.group_by_dropdown.observe(on_group_by_change, names='value')\n",
    "\n",
    "        # Handle selection of aggregate columns\n",
    "        def on_agg_cols_change(change):\n",
    "            self.update_selected_columns(change)\n",
    "        self.agg_cols_dropdown.observe(on_agg_cols_change, names='value')\n",
    "\n",
    "\n",
    "        # Join button click handler\n",
    "        def on_join_button_click(b):           \n",
    "            self.capture_output(self._perform_join)            \n",
    "        self.join_button.on_click(on_join_button_click)\n",
    "        \n",
    "    def _perform_join(self):\n",
    "        \"\"\"Perform the join operation.\"\"\"\n",
    "        group_by = self.group_by_col if self.aggregate_checkbox.value else None\n",
    "        agg_cols = self.selected_cols if self.aggregate_checkbox.value else []\n",
    "\n",
    "        self.enricher.join_chey(\n",
    "                group_by=group_by,\n",
    "                pred=self.predicate_text.value,\n",
    "                rel_str=self.rel_str_text.value,\n",
    "                make_geom=self.make_geom_checkbox.value,\n",
    "                ratio=self.intr_ratio_checkbox.value,\n",
    "                aggr=self.aggregate_checkbox.value,\n",
    "                madre=self.madre_checkbox.value,\n",
    "                cache=self.cache_checkbox.value,\n",
    "                grid_area=self.grid_area_text.value,\n",
    "                *agg_cols\n",
    "        )\n",
    "        print(\"Join operation completed.\")\n",
    "\n",
    "        # Export button click handler\n",
    "        def on_export_button_click(b):\n",
    "            # Capture console output\n",
    "            old_stdout = sys.stdout\n",
    "            sys.stdout = captured_output = StringIO()\n",
    "\n",
    "            try:\n",
    "                self.enricher.export(\n",
    "                    df=self.df_text.value,\n",
    "                    path=self.path_text.value,\n",
    "                    name=self.name_text.value,\n",
    "                    how=self.how_text.value,\n",
    "                    num=self.num_text.value,\n",
    "                    clear=self.clear_checkbox.value\n",
    "                )\n",
    "                print(\"Export operation completed.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {str(e)}\")\n",
    "            finally:\n",
    "                sys.stdout = old_stdout\n",
    "                self.console_output.value += captured_output.getvalue()\n",
    "\n",
    "        self.export_button.on_click(on_export_button_click)\n",
    "\n",
    "        # Clear console button click handler\n",
    "        def on_clear_console_button_click(b):\n",
    "            self.console_output.value = \"\"\n",
    "        self.clear_console_button.on_click(on_clear_console_button_click)\n",
    "\n",
    "    def update_selected_columns(self, change):\n",
    "        \"\"\"Update the list of selected columns for group_by and aggregate_cols.\"\"\"\n",
    "        # Add newly selected columns to the selected list\n",
    "        for col in change[\"new\"]:\n",
    "            if col not in self.selected_cols:\n",
    "                self.selected_cols.append(col)\n",
    "    \n",
    "        # Update the dropdown options to disable already selected columns\n",
    "        available_options = [col for col in self.enricher.df2.columns if col not in self.selected_cols]\n",
    "        self.agg_cols_dropdown.options = available_options\n",
    "    \n",
    "        # Update the display of selected columns\n",
    "        self.selected_agg_cols.options = self.selected_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "\n",
    "obj = Enricher()\n",
    "obj.setup(which=\"sedona\", ex_mem=26, dr_mem=24)\n",
    "path1=\"./data_EU/countries_shp/\"\n",
    "path2=\"./data_EU/census_grid_EU/grids.parquet\"\n",
    "\n",
    "obj.load_datsets(which=\"sedona\", path1=path1, path2=path2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21ed65d09f404f9bbd8e8e80c3439988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HTML(value='<h2>Join</h2>'), HBox(children=(Checkbox(value=False, description='Mâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/27 11:31:44 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "25/01/27 11:31:56 WARN JoinQuery: UseIndex is true, but no index exists. Will build index on the fly.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# GUI\n",
    "\n",
    "obj_ui = EnricherUI(obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/27 11:36:26 WARN JoinQuery: UseIndex is true, but no index exists. Will build index on the fly.\n",
      "[Stage 27:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------+-------+---------+--------------------+--------------------+---------+-------------+--------------------+--------------------+---------+--------------+--------------------+---+-----+-----+------+------+------+----+-----+------+----+-----+------+-------+------------+---------+------------------+\n",
      "|            df1_geom|            df2_geom|       COMM_ID|CNTR_ID|CNTR_CODE|           COMM_NAME|           NAME_ASCI|TRUE_FLAG|     NSI_CODE|            NAME_NSI|           NAME_LATN|NUTS_CODE|           FID|              GRD_ID|  T|    M|    F|Y_LT15|Y_1564|Y_GE65| EMP|  NAT|EU_OTH| OTH| SAME|CHG_IN|CHG_OUT|LAND_SURFACE|POPULATED|CONFIDENTIALSTATUS|\n",
      "+--------------------+--------------------+--------------+-------+---------+--------------------+--------------------+---------+-------------+--------------------+--------------------+---------+--------------+--------------------+---+-----+-----+------+------+------+----+-----+------+----+-----+------+-------+------------+---------+------------------+\n",
      "|MULTIPOLYGON (((1...|POLYGON ((1966000...|ES6535014\u0000\u0000\u0000\u0000\u0000|     ES|       ES|Oliva, La\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000...|Oliva, La\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000...|        T|35014\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000|Oliva, La\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000...|Oliva, La\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000...|    ES704|ES6535014\u0000\u0000\u0000\u0000\u0000|CRS3035RES1000mN1...|259|143.0|116.0|  38.0| 190.0|  29.0|86.0|113.0|  94.0|47.0|220.0|  24.0|   11.0|      0.6115|        1|              NULL|\n",
      "|MULTIPOLYGON (((1...|POLYGON ((1967000...|ES6535014\u0000\u0000\u0000\u0000\u0000|     ES|       ES|Oliva, La\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000...|Oliva, La\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000...|        T|35014\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000|Oliva, La\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000...|Oliva, La\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000...|    ES704|ES6535014\u0000\u0000\u0000\u0000\u0000|CRS3035RES1000mN1...|  4|  4.0|  2.0|   1.0|   2.0|   2.0| 2.0|  4.0|   0.0| 0.0|  4.0|   0.0|    0.0|         1.0|        1|              NULL|\n",
      "|MULTIPOLYGON (((1...|POLYGON ((1968000...|ES6535014\u0000\u0000\u0000\u0000\u0000|     ES|       ES|Oliva, La\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000...|Oliva, La\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000...|        T|35014\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000|Oliva, La\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000...|Oliva, La\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000...|    ES704|ES6535014\u0000\u0000\u0000\u0000\u0000|CRS3035RES1000mN1...|  0|  0.0|  0.0|   0.0|   0.0|   0.0| 0.0|  0.0|   0.0| 0.0|  0.0|   0.0|    0.0|         1.0|        0|              NULL|\n",
      "|MULTIPOLYGON (((1...|POLYGON ((1969000...|ES6535014\u0000\u0000\u0000\u0000\u0000|     ES|       ES|Oliva, La\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000...|Oliva, La\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000...|        T|35014\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000|Oliva, La\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000...|Oliva, La\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000...|    ES704|ES6535014\u0000\u0000\u0000\u0000\u0000|CRS3035RES1000mN1...|  0|  0.0|  0.0|   0.0|   0.0|   0.0| 0.0|  0.0|   0.0| 0.0|  0.0|   0.0|    0.0|         1.0|        0|              NULL|\n",
      "|MULTIPOLYGON (((1...|POLYGON ((1970000...|ES6535014\u0000\u0000\u0000\u0000\u0000|     ES|       ES|Oliva, La\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000...|Oliva, La\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000...|        T|35014\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000|Oliva, La\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000...|Oliva, La\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000...|    ES704|ES6535014\u0000\u0000\u0000\u0000\u0000|CRS3035RES1000mN1...|  0|  0.0|  0.0|   0.0|   0.0|   0.0| 0.0|  0.0|   0.0| 0.0|  0.0|   0.0|    0.0|         1.0|        0|              NULL|\n",
      "+--------------------+--------------------+--------------+-------+---------+--------------------+--------------------+---------+-------------+--------------------+--------------------+---------+--------------+--------------------+---+-----+-----+------+------+------+----+-----+------+----+-----+------+-------+------------+---------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "obj_ui.enricher.res.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/24 14:42:51 WARN Utils: Your hostname, marvin resolves to a loopback address: 127.0.1.1; using 172.20.27.4 instead (on interface eth0)\n",
      "25/01/24 14:42:51 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/data/homes_data/sudheer/benchmark_data/sedona_venv/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /data/homes_data/sudheer/.ivy2/cache\n",
      "The jars for the packages stored in: /data/homes_data/sudheer/.ivy2/jars\n",
      "org.apache.sedona#sedona-spark-shaded-3.5_2.12 added as a dependency\n",
      "org.datasyslab#geotools-wrapper added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-8cfb8944-1123-44e5-8687-12d080f76c5d;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.sedona#sedona-spark-shaded-3.5_2.12;1.7.0 in central\n",
      "\tfound org.datasyslab#geotools-wrapper;1.7.0-28.5 in central\n",
      ":: resolution report :: resolve 261ms :: artifacts dl 10ms\n",
      "\t:: modules in use:\n",
      "\torg.apache.sedona#sedona-spark-shaded-3.5_2.12;1.7.0 from central in [default]\n",
      "\torg.datasyslab#geotools-wrapper;1.7.0-28.5 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-8cfb8944-1123-44e5-8687-12d080f76c5d\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 2 already retrieved (0kB/8ms)\n",
      "25/01/24 14:42:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/01/24 14:42:54 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sedona initialized with 10 cores for parellelism.\n",
      "Make sure the geometry column is named \"geometry\" in the datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded. \n",
      " A.cols: ['geometry', 'COMM_ID', 'CNTR_ID', 'CNTR_CODE', 'COMM_NAME', 'NAME_ASCI', 'TRUE_FLAG', 'NSI_CODE', 'NAME_NSI', 'NAME_LATN', 'NUTS_CODE', 'FID'] \n",
      " \n",
      " B.cols: ['GRD_ID', 'T', 'M', 'F', 'Y_LT15', 'Y_1564', 'Y_GE65', 'EMP', 'NAT', 'EU_OTH', 'OTH', 'SAME', 'CHG_IN', 'CHG_OUT', 'LAND_SURFACE', 'POPULATED', 'CONFIDENTIALSTATUS', 'geometry']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/24 14:43:13 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "25/01/24 14:43:26 WARN JoinQuery: UseIndex is true, but no index exists. Will build index on the fly.\n",
      "25/01/24 14:43:40 WARN JoinQuery: UseIndex is true, but no index exists. Will build index on the fly.\n",
      "25/01/24 15:04:33 WARN MemoryStore: Not enough space to cache rdd_65_78 in memory! (computed 844.5 MiB so far)\n",
      "25/01/24 15:04:33 WARN BlockManager: Persisting block rdd_65_78 to disk instead.\n",
      "25/01/24 15:04:34 WARN MemoryStore: Not enough space to cache rdd_65_75 in memory! (computed 838.1 MiB so far)\n",
      "25/01/24 15:04:34 WARN BlockManager: Persisting block rdd_65_75 to disk instead.\n",
      "25/01/24 15:04:36 WARN MemoryStore: Not enough space to cache rdd_65_173 in memory! (computed 128.6 MiB so far)\n",
      "25/01/24 15:04:36 WARN BlockManager: Persisting block rdd_65_173 to disk instead.\n",
      "25/01/24 15:04:37 WARN MemoryStore: Not enough space to cache rdd_65_163 in memory! (computed 184.9 MiB so far)\n",
      "25/01/24 15:04:37 WARN BlockManager: Persisting block rdd_65_163 to disk instead.\n",
      "25/01/24 15:04:37 WARN MemoryStore: Not enough space to cache rdd_65_127 in memory! (computed 2.4 GiB so far)\n",
      "25/01/24 15:04:37 WARN BlockManager: Persisting block rdd_65_127 to disk instead.\n",
      "25/01/24 15:04:53 WARN MemoryStore: Not enough space to cache rdd_65_104 in memory! (computed 1285.1 MiB so far)\n",
      "25/01/24 15:04:53 WARN BlockManager: Persisting block rdd_65_104 to disk instead.\n",
      "25/01/24 15:05:23 WARN MemoryStore: Not enough space to cache rdd_65_104 in memory! (computed 837.2 MiB so far)\n",
      "25/01/24 15:06:38 WARN MemoryStore: Not enough space to cache rdd_65_173 in memory! (computed 128.6 MiB so far)\n",
      "25/01/24 15:06:40 WARN MemoryStore: Not enough space to cache rdd_65_127 in memory! (computed 686.3 MiB so far)\n",
      "25/01/24 15:06:42 WARN MemoryStore: Not enough space to cache rdd_65_127 in memory! (computed 438.2 MiB so far)\n",
      "25/01/24 15:06:45 WARN MemoryStore: Not enough space to cache rdd_65_173 in memory! (computed 253.2 MiB so far)\n",
      "25/01/24 15:06:49 WARN MemoryStore: Not enough space to cache rdd_65_104 in memory! (computed 837.2 MiB so far)\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cached. 6315546 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/24 15:09:23 WARN JoinQuery: UseIndex is true, but no index exists. Will build index on the fly.\n",
      "[Stage 40:==============================================>      (177 + 10) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cached. 41 rows.\n",
      "join + make geom + intersection areas + aggregate... DONE in 44.35 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# No GUI\n",
    "\n",
    "\n",
    "obj = Enricher()\n",
    "\n",
    "obj.setup(which=\"sedona\", ex_mem=26, dr_mem=24)\n",
    "\n",
    "path1=\"./data_EU/countries_shp/\"\n",
    "path2=\"./data_EU/census_grid_EU/grids.parquet\"\n",
    "\n",
    "obj.load_datsets(which=\"sedona\", path1=path1, path2=path2)\n",
    "\n",
    "agr_cols = ['T', 'M', 'F', 'Y_LT15', 'Y_1564', 'Y_GE65', 'EMP', 'NAT', 'EU_OTH', 'OTH', 'SAME', 'CHG_IN', 'CHG_OUT', 'LAND_SURFACE', 'POPULATED']\n",
    "\n",
    "with obj.get_time(\"join + make geom + intersection areas + aggregate\"):\n",
    "    obj.join_chey('CNTR_ID', *agr_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sedona_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
